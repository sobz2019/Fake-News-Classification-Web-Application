{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b5d4950",
   "metadata": {},
   "source": [
    "# 1. Proposed Algorithms and Pretrained models list\n",
    "\n",
    "***\n",
    "\n",
    "List of proposed algorithms using in this experiment\n",
    "\n",
    "**Machine Learning Models**\n",
    "\n",
    "- SVM\n",
    "- Random Forest\n",
    "- XgBoost\n",
    "- Naive Bayes\n",
    "- KNN\n",
    "- Logistic Regression\n",
    "\n",
    "**Deep Learning Models**\n",
    "\n",
    "- 1 Dimensional Convolutional Neural Network(1d CNN)\n",
    "- Long Short Term Memory Neural Network(LSTM)\n",
    "- Bi Directional Long Short Term Memory Neural Network(Bi-LSTM)\n",
    "\n",
    "\n",
    "**Pretrained Models**\n",
    "\n",
    "- Word2Vec -> GoogleNews-vectors-negative300.bin\n",
    "- Glove -> glove.6B.300d.txt\n",
    "- BERT  -> bert_en_uncased_L-12_H-768_A-12/1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408fae65",
   "metadata": {},
   "source": [
    "*** \n",
    "# 2. Model Training Phase\n",
    "\n",
    "This section includes the general scripts , user defined helper functions and some sample scripts which used in the model development phase for the automatic detection of fake news experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5620072e",
   "metadata": {},
   "source": [
    "## 2.1.  User defined helper functions to create the confusion matrix and normalised confusion matrix \n",
    "\n",
    "The below scripts is using to create the confusion matrix and normalised confusion matrix based on the predictions and actual truth lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbfce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to plot confusion matrix and normalised confusion matrix plot\n",
    "def confusn_mtrx_plot(cm,path):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    # Y_pred_evc = evc_mdl.predict(test_X)\n",
    "    #cm = confusion_matrix(ytrue, y_pred)\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 5), dpi=60)\n",
    "    ax = plt.subplot()\n",
    "    sns.set(font_scale=1.4) # Adjust to fit\n",
    "    sns.heatmap(cm, annot=True, ax=ax, cmap=\"GnBu\", fmt=\"g\");  \n",
    "    #sns.heatmap(cm/np.sum(cm), annot=True, ax=ax[1], cmap=\"GnBu\", fmt=\"g\");  \n",
    "\n",
    "    # Labels, title and ticks\n",
    "    label_font = {'size':'18'}  # Adjust to fit\n",
    "    ax.set_xlabel('Predicted', fontdict=label_font);\n",
    "    ax.set_ylabel('Actuals', fontdict=label_font);\n",
    "\n",
    "    title_font = {'size':'20'}  # Adjust to fit\n",
    "    ax.set_title('Confusion Matrix', fontdict=title_font);\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)  # Adjust to fit\n",
    "    ax.xaxis.set_ticklabels(['Real', 'Fake']);\n",
    "    ax.yaxis.set_ticklabels(['Real', 'Fake']);\n",
    "    #fig.show()\n",
    "    fig.savefig(path)\n",
    "    \n",
    "def norm_confusn_mtrx_plot(cm,path):\n",
    "    fig = plt.figure(figsize=(6, 5), dpi=60)\n",
    "    ax = plt.subplot()\n",
    "    sns.set(font_scale=1.4) # Adjust to fit\n",
    "    sns.heatmap(cm/np.sum(cm), annot=True, ax=ax, cmap=\"GnBu\",fmt='.2%');  \n",
    "\n",
    "    # Labels, title and ticks\n",
    "    label_font = {'size':'18'}  # Adjust to fit\n",
    "    ax.set_xlabel('Predicted', fontdict=label_font);\n",
    "    ax.set_ylabel('Actuals', fontdict=label_font);\n",
    "\n",
    "    title_font = {'size':'18'}  # Adjust to fit\n",
    "    ax.set_title('Normalised Confusion Matrix', fontdict=title_font);\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)  # Adjust to fit\n",
    "    ax.xaxis.set_ticklabels(['Real', 'Fake']);\n",
    "    ax.yaxis.set_ticklabels(['Real', 'Fake']);\n",
    "    fig.savefig(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca28789",
   "metadata": {},
   "source": [
    "## 2.2.  User defined helper functions to find out the accuracy score metrics and creation of model comparison table\n",
    "\n",
    "\n",
    "- The function named **metrics** is using to calculate the score of the different metrics such as Accuracy, Precision, Recall, F1Score and ROC AUC score for the given classifier with test data\n",
    "\n",
    "\n",
    "- The function named **model_comparison_table** is using to create dataframe to list down all the classifiers with the metrics scores for the comparison purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5eeb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    " \n",
    "\n",
    "\n",
    "def metrics(X_test,y_test,clf):\n",
    "    predictions=clf.predict(X_test)\n",
    "    #predictions=(clf.predict_proba(X_test)[:,1] >= 0.3).astype(bool)\n",
    "    print(\"confusion_matrix :\")\n",
    "    print(confusion_matrix(y_test,predictions))\n",
    "    print(\"Accuracy Score :\")\n",
    "    print(accuracy_score(y_test, predictions))\n",
    "    print(\"Classification Report :\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(\"F1 score :\")\n",
    "    print(f1_score(y_test, predictions))\n",
    "    print(\"ROC AUC Score\")\n",
    "    y_pred_proba = clf.predict_proba(X_test)\n",
    "    print(roc_auc_score(y_test, y_pred_proba[:,1]) )\n",
    "    print(\"------------------------------\")\n",
    "\n",
    "    \n",
    "def model_comparison_table(X_test,y_test,classifier_list):\n",
    "    dict_clf={}\n",
    "    for clf_name,clf in classifier_list:\n",
    "        predictions=clf.predict(X_test)\n",
    "        y_pred_proba = clf.predict_proba(X_test)\n",
    "        accuracy=accuracy_score(y_test, predictions)\n",
    "        precision=precision_score(y_test,predictions,average='macro').round(2)\n",
    "        recall=recall_score(y_test,predictions)\n",
    "        f1score=f1_score(y_test,predictions).round(2)\n",
    "        ROC_AUC=roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "        dict_clf[clf_name]=[accuracy,precision,recall,f1score,ROC_AUC]\n",
    "    df_models_scores = pd.DataFrame(dict_clf, index=['Accuracy', 'Precision', 'Recall', 'F1 Score','roc_auc_score'])\n",
    "    return df_models_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ccbc4",
   "metadata": {},
   "source": [
    "## 2.3.  Train-Test Data Split"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2f67fce",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda9dc6c",
   "metadata": {},
   "source": [
    "*** \n",
    "## 2.4  Feature Extraction Sample Scripts  by fitting data using Tokenisation and Pretrained Word Embeddings \n",
    "\n",
    "***\n",
    "### 2.4.1 Tokenisation using TFIDF\n",
    "\n",
    "\n",
    "**Sample scripts of applying TF-IDF tokenisation over the training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480b8e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5cd9f2",
   "metadata": {},
   "source": [
    "*** \n",
    "### 2.4.2 Pretrained Word2Vec Embedding model\n",
    "\n",
    "\n",
    "#### 2.4.2.1 Download the pretrained Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b9cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f291cc8",
   "metadata": {},
   "source": [
    "#### 2.4.2.2 After downloading it, you can load it as follows (if it is in the same directory as the py file or jupyter notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf47ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "%time w2v_model = KeyedVectors.load_word2vec_format(path_to_model, binary=True)\n",
    "print('done loading Word2Vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998f77e1",
   "metadata": {},
   "source": [
    "#### 2.4.2.3 Then inspect the model by getting the list of index of key values from the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3b6883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect the model\n",
    "word2vec_vocab = list(w2v_model.index_to_key)\n",
    "\n",
    "## Converting the lower case\n",
    "word2vec_vocab_lower = [item.lower() for item in word2vec_vocab]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f37636",
   "metadata": {},
   "source": [
    "#### 2.4.2.4 User defined Function to create a feature vector by averaging all embeddings for the given sentence using the below user defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb49f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a feature vector by averaging all embeddings for all sentences\n",
    "def embedding_feats(list_of_lists):\n",
    "    DIMENSION = 300\n",
    "    zero_vector = np.zeros(DIMENSION)\n",
    "    feats = []\n",
    "    for tokens in list_of_lists:\n",
    "        feat_for_this =  np.zeros(DIMENSION)\n",
    "        count_for_this = 0 + 1e-5 # to avoid divide-by-zero \n",
    "        for token in tokens:\n",
    "            if token in w2v_model:\n",
    "                feat_for_this += w2v_model[token]\n",
    "                count_for_this +=1\n",
    "        if(count_for_this!=0):\n",
    "            feats.append(feat_for_this/count_for_this) \n",
    "        else:\n",
    "            feats.append(zero_vector)\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adea496e",
   "metadata": {},
   "source": [
    "#### 2.4.2.5 Then fit the training data and transform both training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd18e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = embedding_feats(X_train)\n",
    "test_vectors = embedding_feats(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca6ecbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c42911a7",
   "metadata": {},
   "source": [
    "*** \n",
    "### 2.4.3 Pretrained Glove Embedding model\n",
    "\n",
    "\n",
    "#### 2.4.3.1 Download the pretrained Glove model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb4eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43661081",
   "metadata": {},
   "source": [
    "#### 2.4.3.2 Load the downloaded the 300 dimension Glove pretrained model \"glove.6B.300d.txt\" in a path and convert to word2vec format\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f168dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "path_to_model = 'Embeddings//glove.6B.300d.txt'\n",
    "output_file = 'Embeddings///gensim_glove.6B.300d.txt'\n",
    "glove2word2vec(path_to_model, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822da5b6",
   "metadata": {},
   "source": [
    "#### 2.4.3.3 Then load the converted glove model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model = KeyedVectors.load_word2vec_format(output_file, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c02340",
   "metadata": {},
   "source": [
    "#### 2.4.3.4 User defined function to create a feature vector by averaging all embeddings for the given sentence using the below user defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbadf529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a feature vector by averaging all embeddings for all sentences\n",
    "def embedding_feats(list_of_lists):\n",
    "    DIMENSION = 300\n",
    "    zero_vector = np.zeros(DIMENSION)\n",
    "    feats = []\n",
    "    for tokens in list_of_lists:\n",
    "        feat_for_this =  np.zeros(DIMENSION)\n",
    "        count_for_this = 0 + 1e-5 # to avoid divide-by-zero \n",
    "        for token in tokens:\n",
    "            if token in w2v_model:\n",
    "                feat_for_this += w2v_model[token]\n",
    "                count_for_this +=1\n",
    "        if(count_for_this!=0):\n",
    "            feats.append(feat_for_this/count_for_this) \n",
    "        else:\n",
    "            feats.append(zero_vector)\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd9e2c3",
   "metadata": {},
   "source": [
    "#### 2.4.3.5 Then fit the training data and transform both training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697dbd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_train_vectors = embedding_feats(X_train)\n",
    "glove_test_vectors = embedding_feats(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1611cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96677024",
   "metadata": {},
   "source": [
    "*** \n",
    "### 2.4.4 Pretrained BERT Embedding model\n",
    "\n",
    "\n",
    "#### 2.4.4.1 Load the Pretrained BERT embedding preprocessor and encoder  model from tensorflow hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11de2ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert preprocessor - https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n",
    "preprocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "# bert encoder - https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/2\n",
    "encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/2\",trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f7df95",
   "metadata": {},
   "source": [
    "Text inputs need to be transformed to numeric token ids and arranged in several Tensors before being input to BERT.\n",
    "Since our dataset is huge and it is not possible to transform full data to numeric token ids , we can do the same by splitting the data into multiple chunks as like below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5fa2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing dataset  - First Set\n",
    "inputs = preprocessor(texts[0:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df949be",
   "metadata": {},
   "source": [
    "After executing the above command, 3 outputs from the preprocessing will be generated that a BERT model would use (input_words_id, input_mask and input_type_ids).\n",
    "Then encode the output and convert it into bert model features which can be feed to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c8a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feeding it to model for vectorization\n",
    "outputs = encoder(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf5cd49",
   "metadata": {},
   "source": [
    "The above output BERT models return a map with 3 important keys: pooled_output, sequence_output, encoder_outputs:\n",
    "\n",
    "- pooled_output represents each input sequence as a whole. The shape is [batch_size, H]. \n",
    "- sequence_output represents each input token in the context. The shape is [batch_size, seq_length, H]. \n",
    "- encoder_outputs are the intermediate activations of the L Transformer block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211aeced",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_output = outputs[\"pooled_output\"]      # [batch_size, 512].\n",
    "sequence_output = outputs[\"sequence_output\"]  # [batch_size, seq_length, 512]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10b7293",
   "metadata": {},
   "source": [
    "Then convert bert encoder sequence outputs to 1 dimension  and save the encoder sequence output to a dataframe for a single chunk.This same process need to do for all the splitted data chunks and then need to merge all the dataframes into a single one , which will feed to the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a4760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining dataframe\n",
    "bertf_df1=pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(sequence_output)):\n",
    "    b=sequence_output[i].numpy().sum(axis=0)\n",
    "    bertf_df1=bertf_df1.append(pd.Series(b),ignore_index=True)\n",
    "print('values added in dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertf_df1 = pd.read_csv(\"Updated//bertf_df1.csv\")\n",
    "bertf_df2 = pd.read_csv(\"Updated//bertf_df2.csv\")\n",
    "bertf_df3 = pd.read_csv(\"Updated//bertf_df3.csv\")\n",
    "bertf_df4 = pd.read_csv(\"Updated//bertf_df4.csv\")\n",
    "\n",
    "# merging both props \n",
    "bertVectors_fulldf=pd.concat([bertf_df1,bertf_df2,bertf_df3,bertf_df4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c8fd40",
   "metadata": {},
   "source": [
    "Then add class label column in the merged bert feature dataframe and then this dataframe will go with train-test data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5eb1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding Class Label\n",
    "bertVectors_fulldf.insert(len(bertVectors_fulldf.columns),'class',isot_full_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0be2fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41e2ae3a",
   "metadata": {},
   "source": [
    "*** \n",
    "## 2.5 Training Algorithm\n",
    "\n",
    "***\n",
    "### 2.5.1 Random Forest\n",
    "\n",
    "\n",
    "**Initiate object for Random Forest model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74535bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf=RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c774fd",
   "metadata": {},
   "source": [
    "Then fit the model and save it to a path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fc4e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf.fit(X_train_tfidf,y_train)\n",
    "\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'outputs//isot_ml_tfidf//isot_ml_RF_tfidf.sav'\n",
    "pickle.dump(rf_clf, open(filename, 'wb'))\n",
    "print('RandomForest - Completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f135bf2",
   "metadata": {},
   "source": [
    "Then predict using test data and measure the accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10087f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf_clf_tuned.predict(X_test_tfidf)\n",
    "print(\"Accuracy score : {}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"Confusion matrix : \\n {}\".format(confusion_matrix(y_test, pred)))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, pred))\n",
    "precision = precision_score(y_test, pred)\n",
    "print(\"Precision : {}\".format(precision))\n",
    "recall = recall_score(y_test, pred)\n",
    "print(\"Recall : {}\".format(recall))\n",
    "f1score = f1_score(y_test, pred)\n",
    "print(\"F1 Score : {}\".format(f1score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbaba85",
   "metadata": {},
   "source": [
    "Plot confusion matrix using the user defined functions as mentioned above earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c3180",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test, pred)\n",
    "path1=\"outputs//isot_ml_tfidf//isot_ml_RF_tfidf_cmtrx.png\"\n",
    "path2=\"outputs//isot_ml_tfidf//isot_ml_RF_tfidf_ncmtrx.png\"\n",
    "confusn_mtrx_plot(cm,path1)\n",
    "norm_confusn_mtrx_plot(cm,path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b26ce1d",
   "metadata": {},
   "source": [
    "***\n",
    "### 2.5.2 CNN\n",
    "\n",
    "\n",
    "**Initiate object for CNN and configure the model check point and early stopping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cd3828",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"outputs//isot_dl_tfidf//model_ISOT_CNN_TFIDF_V2.h5\" # Location to get the model\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "es = EarlyStopping(monitor='val_loss', patience=3,mode='min', verbose=1)\n",
    "callbacks_list = [checkpoint,es]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01acfca9",
   "metadata": {},
   "source": [
    "**Define the model architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c0d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "model=Sequential()\n",
    "model.add(Conv1D(filters=128, kernel_size=3, padding='valid', activation='relu',input_shape=(max_features,1)))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adb2efb",
   "metadata": {},
   "source": [
    "**Fitting the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d563db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "history=model.fit(x_train_tf_cn, y_train, epochs=3, batch_size=32,validation_data=(x_test_tf_cn,y_test), \n",
    "                  callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a130bf37",
   "metadata": {},
   "source": [
    "**Prediction Analysis using Test Data and save the history of metric scores in a csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f2e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test_tf_cn)\n",
    "ytrue = y_test.astype(int).tolist()\n",
    "y_pred2 = np.array((y_pred > 0.5).astype(int)[:,0])\n",
    "precision = precision_score(ytrue, y_pred2)\n",
    "recall = recall_score(ytrue, y_pred2)\n",
    "f1score = f1_score(ytrue, y_pred2)\n",
    "history.history['precision']=precision\n",
    "history.history['recall']=recall\n",
    "history.history['f1score']=f1score\n",
    "hist_df = pd.DataFrame(history.history) \n",
    "hist_df.to_csv(\"outputs//isot_dl_tfidf//model_ISOT_CNN_TFIDF_V2_history.csv\")\n",
    "plot_loss_and_acc_from_hist2(hist_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff277e0",
   "metadata": {},
   "source": [
    "**Measure the Performance Metrics Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe42bc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy score : {}\".format(accuracy_score(ytrue, y_pred2)))\n",
    "print('precision =',precision)\n",
    "print('recall =',recall)\n",
    "print('f1score =',f1score)\n",
    "print(confusion_matrix(ytrue, y_pred2))\n",
    "print(classification_report(ytrue, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2722ab85",
   "metadata": {},
   "source": [
    "**Plot confusion matrix using the user defined functions as mentioned above earlier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87c1f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(ytrue, y_pred2)\n",
    "path1=\"outputs//isot_dl_tfidf//isot_cnn_tfidf_cmtrx.png\"\n",
    "path2=\"outputs//isot_dl_tfidf//isot_cnn_tfidf_ncmtrx.png\"\n",
    "confusn_mtrx_plot(cm,path1)\n",
    "norm_confusn_mtrx_plot(cm,path2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
