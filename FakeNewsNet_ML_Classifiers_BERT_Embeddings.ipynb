{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aedf7bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a376fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7640691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e6003e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 20:14:00.955981: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-19 20:14:01.674480: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfs/software/ada/python/anaconda/2020.11/3.8/lib:/gpfs/software/ada/cuda/10.2.89/lib64:/gpfs/software/ada/cuda/10.2.89/lib/lib64\n",
      "2022-06-19 20:14:01.674537: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /gpfs/home/psc21zcu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /gpfs/home/psc21zcu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /gpfs/home/psc21zcu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /gpfs/home/psc21zcu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import json\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "import tldextract   # Accurately separates a URL's subdomain, domain, and public suffix\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import re\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from imblearn.over_sampling import SMOTE,ADASYN\n",
    "from collections import Counter\n",
    "import nltk \n",
    "import spacy\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from wordcloud import WordCloud, ImageColorGenerator,STOPWORDS\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import STOPWORDS as gensim_stopwords\n",
    "import copy\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords,wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer,LancasterStemmer\n",
    "from sklearn.metrics import f1_score\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43c52441",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "#pd.set_option('display.height', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b0a257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldr_pol_real = 'input_dataset//fakenewsnet//politifact//real//'\n",
    "foldr_pol_fake = 'input_dataset//fakenewsnet//politifact//fake//'\n",
    "foldr_gos_real = 'input_dataset//fakenewsnet//gossipcop//real//'\n",
    "foldr_gos_fake = 'input_dataset//fakenewsnet//gossipcop//fake//'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a654d7",
   "metadata": {},
   "source": [
    "##### Function to extract or convert JSON content to News Content format in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cef3289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_newscontent(datapath):\n",
    "    dictlist = []\n",
    "    cols = ['url','text','title','authors','num_images','domain']\n",
    "    folders = glob.glob(datapath+'/*')\n",
    "    for index, subdir in enumerate(folders):\n",
    "        path_file = glob.glob(subdir+'/*')\n",
    "        #check whether file path is valid or not\n",
    "        if len(path_file) == 1:\n",
    "            file = open(path_file[0]).read()\n",
    "            jsondata = json.loads(file)\n",
    "            thedict = {'url':jsondata['url'],'title':jsondata['title'],'text':jsondata['text'],\n",
    "                   'num_images':len(jsondata['images']),'authors':str(jsondata['authors'])}\n",
    "            extrt_url = tldextract.extract(jsondata['url'])\n",
    "            thedict['domain'] = extrt_url.domain\n",
    "            dictlist.append(thedict)\n",
    "    df=pd.DataFrame(dictlist,columns=cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb801c6",
   "metadata": {},
   "source": [
    "##### Converting seperate dataframes for Politfact fake and real and Gossip fake and real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0dce67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 312.7435884475708 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# get the start time\n",
    "st = time.time()\n",
    "\n",
    "df_pol_real = json_to_newscontent(foldr_pol_real)\n",
    "df_pol_fake = json_to_newscontent(foldr_pol_fake)\n",
    "df_gos_real = json_to_newscontent(foldr_gos_real)\n",
    "df_gos_fake = json_to_newscontent(foldr_gos_fake)\n",
    "\n",
    "# get the end time\n",
    "et = time.time()\n",
    "\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1347127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaned dataset\n",
    "df_pol_real = df_pol_real.loc[df_pol_real[\"text\"] != '' ]\n",
    "df_pol_fake = df_pol_fake.loc[df_pol_fake[\"text\"] != '' ]\n",
    "df_gos_real = df_gos_real.loc[df_gos_real[\"text\"] != '' ]\n",
    "df_gos_fake = df_gos_fake.loc[df_gos_fake[\"text\"] != '' ]\n",
    "\n",
    "df_pol_real.reset_index(drop=True,inplace=True)\n",
    "df_pol_fake.reset_index(drop=True,inplace=True)\n",
    "df_gos_real.reset_index(drop=True,inplace=True)\n",
    "df_gos_fake.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad3ee4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pol_real['Category'] = 'Politics' \n",
    "df_pol_fake['Category'] = 'Politics'\n",
    "df_gos_real['Category'] = 'Gossips'\n",
    "df_gos_fake['Category'] = 'Gossips'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a425f0b",
   "metadata": {},
   "source": [
    "##### Add response variable 'class' based on True=1 or Fake=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "334a7825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pol_real['class'] = 0 #True\n",
    "df_pol_fake['class'] = 1 #Fake\n",
    "df_gos_real['class'] = 0\n",
    "df_gos_fake['class'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59128b5b",
   "metadata": {},
   "source": [
    "##### Storing dataframe to csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6728ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pol_real.to_csv('Updated//df_pol_real.csv', index=False)\n",
    "df_pol_fake.to_csv('Updated//df_pol_fake.csv', index=False)\n",
    "df_gos_real.to_csv('Updated//df_gos_real.csv', index=False)\n",
    "df_gos_fake.to_csv('Updated//df_gos_fake.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9871bf0",
   "metadata": {},
   "source": [
    "#### Creating dataframe from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5a8ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #creating a data frame\n",
    "df_pol_real = pd.read_csv(\"Updated//df_pol_real.csv\")\n",
    "df_pol_fake = pd.read_csv(\"Updated//df_pol_fake.csv\")\n",
    "df_gos_real = pd.read_csv(\"Updated//df_gos_real.csv\")\n",
    "df_gos_fake = pd.read_csv(\"Updated//df_gos_fake.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befea89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pol_real.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
    "# df_pol_fake.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
    "# df_gos_real.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
    "# df_gos_fake.drop(columns=['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b06552bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df_pol_real,df_pol_fake,df_gos_real,df_gos_fake]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "247d7811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine df's into one\n",
    "df = pd.concat(df_list).reset_index(drop=True)\n",
    "total_rows = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "483f2611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75.193989\n",
       "1    24.806011\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts() / df.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed064c5",
   "metadata": {},
   "source": [
    "##### combining title and text to full text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fb81e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20362, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fulltext']=df['title']+'.'+df['text']\n",
    "#df2=df2.drop(columns=['url', 'text','title','authors','num_images','domain','Category','url_filter'], axis=1)\n",
    "df=df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f3a097",
   "metadata": {},
   "source": [
    "### Saving Fulldataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1592759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('Updated//full_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bf8905",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcc1473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a data frame\n",
    "df = pd.read_csv(\"Updated//full_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cae4c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterd_df=df[['fulltext','class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97fe2eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fulltext</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rick Santorum: By amending constitution, we can balance the budget for good.Rick Santorum: By amending constitution, we can balance the budget for good\\n\\nBy RICK SANTORUM\\n\\nLast summer, we saw a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN's Don Lemon: Bill O'Reilly's Criticism Of Black Community \"Doesn't Go Far Enough\".Posted on July 27, 2013\\n\\nCNN's Don Lemon: Bill O'Reilly's Criticism Of Black Community \"Doesn't Go Far Enoug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                  fulltext  class\n",
       "0  Rick Santorum: By amending constitution, we can balance the budget for good.Rick Santorum: By amending constitution, we can balance the budget for good\\n\\nBy RICK SANTORUM\\n\\nLast summer, we saw a...      0\n",
       "1  CNN's Don Lemon: Bill O'Reilly's Criticism Of Black Community \"Doesn't Go Far Enough\".Posted on July 27, 2013\\n\\nCNN's Don Lemon: Bill O'Reilly's Criticism Of Black Community \"Doesn't Go Far Enoug...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filterd_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a9cc19",
   "metadata": {},
   "source": [
    "### Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60f213f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the built in cleaner in gensim for basic text preprocessing\n",
    "# filterd_df['cleantext'] = filterd_df['fulltext'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "# filterd_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf4e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transforming and creation of dataframe with Cleaned Text Column and class label\n",
    "## Tranforming **cleanedtext** column from list of arrays to string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b68365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filterd_df['cleantext'] = filterd_df['cleantext'].apply(lambda x: x[0:-1])\n",
    "# filterd_df['cleantext'] = [','.join(map(str, l)) for l in filterd_df['cleantext']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c7dd1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_format(text):\n",
    "#     clean_text=re.sub('\\[[^]]*\\]', ' ', str(text))\n",
    "#     clean_text = re.sub('[^a-zA-Z]',' ',clean_text)  # replaces non-alphabets with spaces\n",
    "#     clean_text=re.sub(r' {2,}',' ',clean_text)\n",
    "#     return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71f6a60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filterd_df['cleantext']=filterd_df['cleantext'].apply(clean_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6a5ab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filterd_df=filterd_df[['cleantext','class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06523e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filterd_df = filterd_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eaef66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filterd_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8bd6a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fulltext</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rick Santorum: By amending constitution, we can balance the budget for good.Rick Santorum: By amending constitution, we can balance the budget for good\\n\\nBy RICK SANTORUM\\n\\nLast summer, we saw a great groundswell of national support to get our fiscal house in order by cutting and capping federal spending and passing a balanced budget amendment to the Constitution. However, the President refused to lead and instead pushed the tough decisions to a bureaucratic Washington committee to solve the problem, and though it was named the 'Supercommittee' it couldn't even agree on cutting Post-It Notes from the office supply closet. Now, because of the inaction, we are faced with drastic defense cuts at a time when reports show a nuclear Iran has emerged as a clear and present danger.I supported the 'Cut, Cap, and Balance' movement, but the reality is that what we really need is 'Balance, Balance, Grow' - because without a balanced budget amendment, and a path to economic prosperity, we can...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  fulltext  class\n",
       "0  Rick Santorum: By amending constitution, we can balance the budget for good.Rick Santorum: By amending constitution, we can balance the budget for good\\n\\nBy RICK SANTORUM\\n\\nLast summer, we saw a great groundswell of national support to get our fiscal house in order by cutting and capping federal spending and passing a balanced budget amendment to the Constitution. However, the President refused to lead and instead pushed the tough decisions to a bureaucratic Washington committee to solve the problem, and though it was named the 'Supercommittee' it couldn't even agree on cutting Post-It Notes from the office supply closet. Now, because of the inaction, we are faced with drastic defense cuts at a time when reports show a nuclear Iran has emerged as a clear and present danger.I supported the 'Cut, Cap, and Balance' movement, but the reality is that what we really need is 'Balance, Balance, Grow' - because without a balanced budget amendment, and a path to economic prosperity, we can...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filterd_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08647ab",
   "metadata": {},
   "source": [
    "### BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2deb574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
    "#https://androidkt.com/simple-text-classification-using-bert-in-tensorflow-keras-2-0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "635f9552",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=filterd_df['fulltext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4e45e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 20:14:28.150575: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfs/software/ada/python/anaconda/2020.11/3.8/lib:/gpfs/software/ada/cuda/10.2.89/lib64:/gpfs/software/ada/cuda/10.2.89/lib/lib64\n",
      "2022-06-19 20:14:28.150780: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfs/software/ada/python/anaconda/2020.11/3.8/lib:/gpfs/software/ada/cuda/10.2.89/lib64:/gpfs/software/ada/cuda/10.2.89/lib/lib64\n",
      "2022-06-19 20:14:28.150926: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfs/software/ada/python/anaconda/2020.11/3.8/lib:/gpfs/software/ada/cuda/10.2.89/lib64:/gpfs/software/ada/cuda/10.2.89/lib/lib64\n",
      "2022-06-19 20:14:28.299168: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfs/software/ada/python/anaconda/2020.11/3.8/lib:/gpfs/software/ada/cuda/10.2.89/lib64:/gpfs/software/ada/cuda/10.2.89/lib/lib64\n",
      "2022-06-19 20:14:28.299502: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfs/software/ada/python/anaconda/2020.11/3.8/lib:/gpfs/software/ada/cuda/10.2.89/lib64:/gpfs/software/ada/cuda/10.2.89/lib/lib64\n",
      "2022-06-19 20:14:28.299808: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfs/software/ada/python/anaconda/2020.11/3.8/lib:/gpfs/software/ada/cuda/10.2.89/lib64:/gpfs/software/ada/cuda/10.2.89/lib/lib64\n",
      "2022-06-19 20:14:28.299872: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-06-19 20:14:28.301545: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# bert preprocessor - https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n",
    "preprocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "# bert encoder - https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/2\n",
    "encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/2\",trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef52e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing dataset  - First Set\n",
    "inputs = preprocessor(texts[0:10000])\n",
    "# feeding it to model for vectorization\n",
    "outputs = encoder(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d40d0e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20362"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98ccaabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sequence_output', 'encoder_outputs', 'pooled_output', 'default'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64b1e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_output = outputs[\"pooled_output\"]      # [batch_size, 512].\n",
    "sequence_output = outputs[\"sequence_output\"]  # [batch_size, seq_length, 512]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "899d4680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cc9cd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 128, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1760413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining dataframe\n",
    "bertf_df1=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "094c334a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values added in dataframe\n"
     ]
    }
   ],
   "source": [
    "## Converting bert encoder sequence output to 1 dimension for ML Model training\n",
    "\n",
    "for i in range(0,len(sequence_output)):\n",
    "    b=sequence_output[i].numpy().sum(axis=0)\n",
    "    bertf_df1=bertf_df1.append(pd.Series(b),ignore_index=True)\n",
    "print('values added in dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27921f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 512)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertf_df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd31b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f14a28da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing dataset  - Second Set\n",
    "inputs2 = preprocessor(texts[10000:21000])\n",
    "# feeding it to model for vectorization\n",
    "outputs2 = encoder(inputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "031213b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_output2 = outputs2[\"pooled_output\"]      # [batch_size, 512].\n",
    "sequence_output2 = outputs2[\"sequence_output\"]  # [batch_size, seq_length, 512]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4063ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertf_df2=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c5d95d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values added in dataframe\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(sequence_output2)):\n",
    "    b=sequence_output2[i].numpy().sum(axis=0)\n",
    "    bertf_df2=bertf_df2.append(pd.Series(b),ignore_index=True)\n",
    "print('values added in dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421b7620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "276113ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging both props \n",
    "bertVectors_fulldf=pd.concat([bertf_df1,bertf_df2])\n",
    "bertVectors_fulldf.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b53b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding class labels\n",
    "bertVectors_fulldf.insert(len(bertVectors_fulldf.columns),'class',filterd_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b081316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15311\n",
       "1     5051\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertVectors_fulldf['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdb4d1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>...</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>267</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>284</th>\n",
       "      <th>285</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "      <th>301</th>\n",
       "      <th>302</th>\n",
       "      <th>303</th>\n",
       "      <th>304</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>313</th>\n",
       "      <th>314</th>\n",
       "      <th>315</th>\n",
       "      <th>316</th>\n",
       "      <th>317</th>\n",
       "      <th>318</th>\n",
       "      <th>319</th>\n",
       "      <th>320</th>\n",
       "      <th>321</th>\n",
       "      <th>322</th>\n",
       "      <th>323</th>\n",
       "      <th>324</th>\n",
       "      <th>325</th>\n",
       "      <th>326</th>\n",
       "      <th>327</th>\n",
       "      <th>328</th>\n",
       "      <th>329</th>\n",
       "      <th>330</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "      <th>334</th>\n",
       "      <th>335</th>\n",
       "      <th>336</th>\n",
       "      <th>337</th>\n",
       "      <th>338</th>\n",
       "      <th>339</th>\n",
       "      <th>340</th>\n",
       "      <th>341</th>\n",
       "      <th>342</th>\n",
       "      <th>343</th>\n",
       "      <th>344</th>\n",
       "      <th>345</th>\n",
       "      <th>346</th>\n",
       "      <th>347</th>\n",
       "      <th>348</th>\n",
       "      <th>349</th>\n",
       "      <th>350</th>\n",
       "      <th>351</th>\n",
       "      <th>352</th>\n",
       "      <th>353</th>\n",
       "      <th>354</th>\n",
       "      <th>355</th>\n",
       "      <th>356</th>\n",
       "      <th>357</th>\n",
       "      <th>358</th>\n",
       "      <th>359</th>\n",
       "      <th>360</th>\n",
       "      <th>361</th>\n",
       "      <th>362</th>\n",
       "      <th>363</th>\n",
       "      <th>364</th>\n",
       "      <th>365</th>\n",
       "      <th>366</th>\n",
       "      <th>367</th>\n",
       "      <th>368</th>\n",
       "      <th>369</th>\n",
       "      <th>370</th>\n",
       "      <th>371</th>\n",
       "      <th>372</th>\n",
       "      <th>373</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>384</th>\n",
       "      <th>385</th>\n",
       "      <th>386</th>\n",
       "      <th>387</th>\n",
       "      <th>388</th>\n",
       "      <th>389</th>\n",
       "      <th>390</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>399</th>\n",
       "      <th>400</th>\n",
       "      <th>401</th>\n",
       "      <th>402</th>\n",
       "      <th>403</th>\n",
       "      <th>404</th>\n",
       "      <th>405</th>\n",
       "      <th>406</th>\n",
       "      <th>407</th>\n",
       "      <th>408</th>\n",
       "      <th>409</th>\n",
       "      <th>410</th>\n",
       "      <th>411</th>\n",
       "      <th>412</th>\n",
       "      <th>413</th>\n",
       "      <th>414</th>\n",
       "      <th>415</th>\n",
       "      <th>416</th>\n",
       "      <th>417</th>\n",
       "      <th>418</th>\n",
       "      <th>419</th>\n",
       "      <th>420</th>\n",
       "      <th>421</th>\n",
       "      <th>422</th>\n",
       "      <th>423</th>\n",
       "      <th>424</th>\n",
       "      <th>425</th>\n",
       "      <th>426</th>\n",
       "      <th>427</th>\n",
       "      <th>428</th>\n",
       "      <th>429</th>\n",
       "      <th>430</th>\n",
       "      <th>431</th>\n",
       "      <th>432</th>\n",
       "      <th>433</th>\n",
       "      <th>434</th>\n",
       "      <th>435</th>\n",
       "      <th>436</th>\n",
       "      <th>437</th>\n",
       "      <th>438</th>\n",
       "      <th>439</th>\n",
       "      <th>440</th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "      <th>445</th>\n",
       "      <th>446</th>\n",
       "      <th>447</th>\n",
       "      <th>448</th>\n",
       "      <th>449</th>\n",
       "      <th>450</th>\n",
       "      <th>451</th>\n",
       "      <th>452</th>\n",
       "      <th>453</th>\n",
       "      <th>454</th>\n",
       "      <th>455</th>\n",
       "      <th>456</th>\n",
       "      <th>457</th>\n",
       "      <th>458</th>\n",
       "      <th>459</th>\n",
       "      <th>460</th>\n",
       "      <th>461</th>\n",
       "      <th>462</th>\n",
       "      <th>463</th>\n",
       "      <th>464</th>\n",
       "      <th>465</th>\n",
       "      <th>466</th>\n",
       "      <th>467</th>\n",
       "      <th>468</th>\n",
       "      <th>469</th>\n",
       "      <th>470</th>\n",
       "      <th>471</th>\n",
       "      <th>472</th>\n",
       "      <th>473</th>\n",
       "      <th>474</th>\n",
       "      <th>475</th>\n",
       "      <th>476</th>\n",
       "      <th>477</th>\n",
       "      <th>478</th>\n",
       "      <th>479</th>\n",
       "      <th>480</th>\n",
       "      <th>481</th>\n",
       "      <th>482</th>\n",
       "      <th>483</th>\n",
       "      <th>484</th>\n",
       "      <th>485</th>\n",
       "      <th>486</th>\n",
       "      <th>487</th>\n",
       "      <th>488</th>\n",
       "      <th>489</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.556551</td>\n",
       "      <td>17.010456</td>\n",
       "      <td>31.388668</td>\n",
       "      <td>-59.826038</td>\n",
       "      <td>22.785978</td>\n",
       "      <td>-40.389637</td>\n",
       "      <td>63.132030</td>\n",
       "      <td>84.202469</td>\n",
       "      <td>-16.992029</td>\n",
       "      <td>-23.151354</td>\n",
       "      <td>43.602962</td>\n",
       "      <td>-49.792343</td>\n",
       "      <td>19.467327</td>\n",
       "      <td>-48.555180</td>\n",
       "      <td>-24.660128</td>\n",
       "      <td>23.610239</td>\n",
       "      <td>68.322159</td>\n",
       "      <td>-24.381779</td>\n",
       "      <td>-0.276951</td>\n",
       "      <td>-0.942664</td>\n",
       "      <td>-23.207857</td>\n",
       "      <td>22.574673</td>\n",
       "      <td>-25.435923</td>\n",
       "      <td>-8.476034</td>\n",
       "      <td>24.444014</td>\n",
       "      <td>-9.494406</td>\n",
       "      <td>4.695382</td>\n",
       "      <td>41.938358</td>\n",
       "      <td>-6.322362</td>\n",
       "      <td>-27.365942</td>\n",
       "      <td>3.681536</td>\n",
       "      <td>-79.809784</td>\n",
       "      <td>44.775520</td>\n",
       "      <td>-38.007759</td>\n",
       "      <td>-14.645349</td>\n",
       "      <td>14.415798</td>\n",
       "      <td>9.520861</td>\n",
       "      <td>-65.712296</td>\n",
       "      <td>5.570489</td>\n",
       "      <td>68.280205</td>\n",
       "      <td>14.519122</td>\n",
       "      <td>-17.480473</td>\n",
       "      <td>46.555386</td>\n",
       "      <td>-24.409235</td>\n",
       "      <td>60.196117</td>\n",
       "      <td>51.608974</td>\n",
       "      <td>20.218319</td>\n",
       "      <td>111.037277</td>\n",
       "      <td>20.729141</td>\n",
       "      <td>6.164212</td>\n",
       "      <td>40.037346</td>\n",
       "      <td>20.915165</td>\n",
       "      <td>-49.550720</td>\n",
       "      <td>-8.859608</td>\n",
       "      <td>17.657154</td>\n",
       "      <td>-64.730644</td>\n",
       "      <td>4.080844</td>\n",
       "      <td>25.650654</td>\n",
       "      <td>11.049224</td>\n",
       "      <td>39.231117</td>\n",
       "      <td>1.717297</td>\n",
       "      <td>-38.349976</td>\n",
       "      <td>-51.245243</td>\n",
       "      <td>62.720028</td>\n",
       "      <td>13.244308</td>\n",
       "      <td>56.438663</td>\n",
       "      <td>-29.142439</td>\n",
       "      <td>17.777523</td>\n",
       "      <td>16.075716</td>\n",
       "      <td>32.840721</td>\n",
       "      <td>73.021126</td>\n",
       "      <td>-1.106223</td>\n",
       "      <td>43.724163</td>\n",
       "      <td>110.561844</td>\n",
       "      <td>5.694403</td>\n",
       "      <td>-3.568817</td>\n",
       "      <td>-6.633853</td>\n",
       "      <td>-20.060560</td>\n",
       "      <td>-20.269951</td>\n",
       "      <td>-90.533340</td>\n",
       "      <td>-27.684378</td>\n",
       "      <td>2.509365</td>\n",
       "      <td>0.751597</td>\n",
       "      <td>59.583221</td>\n",
       "      <td>-31.484814</td>\n",
       "      <td>-37.511806</td>\n",
       "      <td>-12.505559</td>\n",
       "      <td>-8.637518</td>\n",
       "      <td>-2.638591</td>\n",
       "      <td>57.80661</td>\n",
       "      <td>-27.497965</td>\n",
       "      <td>70.625862</td>\n",
       "      <td>5.287386</td>\n",
       "      <td>-10.089879</td>\n",
       "      <td>-24.389599</td>\n",
       "      <td>-21.589941</td>\n",
       "      <td>-29.910767</td>\n",
       "      <td>-16.954830</td>\n",
       "      <td>5.852044</td>\n",
       "      <td>67.251831</td>\n",
       "      <td>12.467425</td>\n",
       "      <td>26.722008</td>\n",
       "      <td>74.665611</td>\n",
       "      <td>-45.834213</td>\n",
       "      <td>-27.048599</td>\n",
       "      <td>46.073143</td>\n",
       "      <td>-10.609952</td>\n",
       "      <td>-4.713609</td>\n",
       "      <td>-37.950188</td>\n",
       "      <td>22.113008</td>\n",
       "      <td>22.008308</td>\n",
       "      <td>19.812160</td>\n",
       "      <td>-87.337875</td>\n",
       "      <td>-59.416115</td>\n",
       "      <td>-5.307872</td>\n",
       "      <td>37.954582</td>\n",
       "      <td>-58.814655</td>\n",
       "      <td>-40.410023</td>\n",
       "      <td>67.103203</td>\n",
       "      <td>-9.136406</td>\n",
       "      <td>-10.947894</td>\n",
       "      <td>-9.197604</td>\n",
       "      <td>-19.980762</td>\n",
       "      <td>12.875637</td>\n",
       "      <td>4.647591</td>\n",
       "      <td>46.636059</td>\n",
       "      <td>-30.788107</td>\n",
       "      <td>-38.222744</td>\n",
       "      <td>36.502457</td>\n",
       "      <td>7.888191</td>\n",
       "      <td>-53.950577</td>\n",
       "      <td>-38.763725</td>\n",
       "      <td>4.683434</td>\n",
       "      <td>-76.262459</td>\n",
       "      <td>-12.632508</td>\n",
       "      <td>33.230438</td>\n",
       "      <td>-33.218147</td>\n",
       "      <td>-38.273003</td>\n",
       "      <td>60.519566</td>\n",
       "      <td>-55.548923</td>\n",
       "      <td>21.099266</td>\n",
       "      <td>24.372196</td>\n",
       "      <td>19.415829</td>\n",
       "      <td>48.136097</td>\n",
       "      <td>54.441914</td>\n",
       "      <td>-29.664719</td>\n",
       "      <td>-9.153059</td>\n",
       "      <td>61.043640</td>\n",
       "      <td>-31.490051</td>\n",
       "      <td>-112.432663</td>\n",
       "      <td>-19.331478</td>\n",
       "      <td>46.725330</td>\n",
       "      <td>9.383484</td>\n",
       "      <td>14.873656</td>\n",
       "      <td>-1.091031</td>\n",
       "      <td>1.271348</td>\n",
       "      <td>3.287261</td>\n",
       "      <td>-2.009163</td>\n",
       "      <td>-30.760050</td>\n",
       "      <td>-30.436218</td>\n",
       "      <td>14.952808</td>\n",
       "      <td>18.419436</td>\n",
       "      <td>29.612751</td>\n",
       "      <td>59.370369</td>\n",
       "      <td>34.593708</td>\n",
       "      <td>-19.635996</td>\n",
       "      <td>50.557961</td>\n",
       "      <td>-36.320408</td>\n",
       "      <td>-65.584396</td>\n",
       "      <td>30.164946</td>\n",
       "      <td>98.545799</td>\n",
       "      <td>-26.293577</td>\n",
       "      <td>-4.078367</td>\n",
       "      <td>10.270546</td>\n",
       "      <td>23.894571</td>\n",
       "      <td>-6.337955</td>\n",
       "      <td>16.216356</td>\n",
       "      <td>39.860119</td>\n",
       "      <td>74.214920</td>\n",
       "      <td>-38.005817</td>\n",
       "      <td>47.595745</td>\n",
       "      <td>5.964079</td>\n",
       "      <td>-849.917603</td>\n",
       "      <td>34.075047</td>\n",
       "      <td>-11.063751</td>\n",
       "      <td>17.136820</td>\n",
       "      <td>-25.357260</td>\n",
       "      <td>-0.509272</td>\n",
       "      <td>13.924665</td>\n",
       "      <td>-38.921009</td>\n",
       "      <td>-22.454096</td>\n",
       "      <td>34.336700</td>\n",
       "      <td>59.178024</td>\n",
       "      <td>39.083691</td>\n",
       "      <td>39.124416</td>\n",
       "      <td>-1.147380</td>\n",
       "      <td>-39.004841</td>\n",
       "      <td>-22.438942</td>\n",
       "      <td>-42.472679</td>\n",
       "      <td>-8.890372</td>\n",
       "      <td>-53.831310</td>\n",
       "      <td>15.963998</td>\n",
       "      <td>5.907835</td>\n",
       "      <td>63.313263</td>\n",
       "      <td>50.157925</td>\n",
       "      <td>6.551021</td>\n",
       "      <td>-43.251812</td>\n",
       "      <td>-40.627361</td>\n",
       "      <td>14.976477</td>\n",
       "      <td>-6.637170</td>\n",
       "      <td>-7.116735</td>\n",
       "      <td>10.555429</td>\n",
       "      <td>-25.185091</td>\n",
       "      <td>26.891237</td>\n",
       "      <td>-0.245195</td>\n",
       "      <td>-46.709976</td>\n",
       "      <td>-7.828382</td>\n",
       "      <td>-22.627840</td>\n",
       "      <td>1.802352</td>\n",
       "      <td>61.975979</td>\n",
       "      <td>29.072058</td>\n",
       "      <td>2.272201</td>\n",
       "      <td>24.476221</td>\n",
       "      <td>12.740591</td>\n",
       "      <td>23.313953</td>\n",
       "      <td>12.976930</td>\n",
       "      <td>41.204041</td>\n",
       "      <td>29.900862</td>\n",
       "      <td>-32.610695</td>\n",
       "      <td>-12.696423</td>\n",
       "      <td>-33.097515</td>\n",
       "      <td>-51.407215</td>\n",
       "      <td>12.968203</td>\n",
       "      <td>9.110934</td>\n",
       "      <td>17.925501</td>\n",
       "      <td>-20.052872</td>\n",
       "      <td>-4.232791</td>\n",
       "      <td>54.170078</td>\n",
       "      <td>-43.464672</td>\n",
       "      <td>-24.290796</td>\n",
       "      <td>5.506371</td>\n",
       "      <td>38.109146</td>\n",
       "      <td>-7.741554</td>\n",
       "      <td>-11.476376</td>\n",
       "      <td>-4.175846</td>\n",
       "      <td>2.860617</td>\n",
       "      <td>-8.206497</td>\n",
       "      <td>-1.903335</td>\n",
       "      <td>81.744766</td>\n",
       "      <td>33.409828</td>\n",
       "      <td>...</td>\n",
       "      <td>19.161411</td>\n",
       "      <td>3.992487</td>\n",
       "      <td>-21.862389</td>\n",
       "      <td>-20.661762</td>\n",
       "      <td>11.231766</td>\n",
       "      <td>58.712265</td>\n",
       "      <td>27.022552</td>\n",
       "      <td>55.354141</td>\n",
       "      <td>36.132755</td>\n",
       "      <td>-61.173531</td>\n",
       "      <td>-25.761839</td>\n",
       "      <td>-10.999088</td>\n",
       "      <td>-64.929924</td>\n",
       "      <td>-40.931515</td>\n",
       "      <td>26.480803</td>\n",
       "      <td>-9.809968</td>\n",
       "      <td>43.818893</td>\n",
       "      <td>-23.315437</td>\n",
       "      <td>-11.041743</td>\n",
       "      <td>-51.430466</td>\n",
       "      <td>-8.270232</td>\n",
       "      <td>10.059938</td>\n",
       "      <td>-71.112213</td>\n",
       "      <td>19.979097</td>\n",
       "      <td>32.454544</td>\n",
       "      <td>-29.839439</td>\n",
       "      <td>-15.249496</td>\n",
       "      <td>18.712160</td>\n",
       "      <td>-16.958525</td>\n",
       "      <td>-64.093727</td>\n",
       "      <td>35.438137</td>\n",
       "      <td>-5.034605</td>\n",
       "      <td>-26.102144</td>\n",
       "      <td>-8.258367</td>\n",
       "      <td>40.100033</td>\n",
       "      <td>-33.159740</td>\n",
       "      <td>96.662415</td>\n",
       "      <td>2.077320</td>\n",
       "      <td>23.634781</td>\n",
       "      <td>-7.190621</td>\n",
       "      <td>-20.528114</td>\n",
       "      <td>10.953620</td>\n",
       "      <td>0.715644</td>\n",
       "      <td>-39.609165</td>\n",
       "      <td>-13.449426</td>\n",
       "      <td>-29.081539</td>\n",
       "      <td>-24.678802</td>\n",
       "      <td>39.423264</td>\n",
       "      <td>-31.450626</td>\n",
       "      <td>24.779564</td>\n",
       "      <td>16.608816</td>\n",
       "      <td>-22.171679</td>\n",
       "      <td>-28.825167</td>\n",
       "      <td>14.680913</td>\n",
       "      <td>39.313812</td>\n",
       "      <td>14.856753</td>\n",
       "      <td>0.017121</td>\n",
       "      <td>-7.328357</td>\n",
       "      <td>-47.685780</td>\n",
       "      <td>-26.487274</td>\n",
       "      <td>-48.240578</td>\n",
       "      <td>-50.572430</td>\n",
       "      <td>38.064968</td>\n",
       "      <td>0.701256</td>\n",
       "      <td>-6.009074</td>\n",
       "      <td>-73.383156</td>\n",
       "      <td>-8.664215</td>\n",
       "      <td>41.563145</td>\n",
       "      <td>0.892207</td>\n",
       "      <td>-22.694223</td>\n",
       "      <td>-11.169395</td>\n",
       "      <td>23.253736</td>\n",
       "      <td>27.601736</td>\n",
       "      <td>30.414112</td>\n",
       "      <td>-16.126633</td>\n",
       "      <td>-23.468775</td>\n",
       "      <td>51.786972</td>\n",
       "      <td>29.223194</td>\n",
       "      <td>22.808187</td>\n",
       "      <td>-56.214920</td>\n",
       "      <td>5.355277</td>\n",
       "      <td>13.041296</td>\n",
       "      <td>-6.660851</td>\n",
       "      <td>-41.371964</td>\n",
       "      <td>31.547384</td>\n",
       "      <td>11.386836</td>\n",
       "      <td>75.073738</td>\n",
       "      <td>21.275158</td>\n",
       "      <td>-3.354958</td>\n",
       "      <td>-65.665466</td>\n",
       "      <td>-10.052788</td>\n",
       "      <td>45.558231</td>\n",
       "      <td>-76.270134</td>\n",
       "      <td>29.730227</td>\n",
       "      <td>-1.623319</td>\n",
       "      <td>-12.565716</td>\n",
       "      <td>-56.678497</td>\n",
       "      <td>-24.496201</td>\n",
       "      <td>-33.074398</td>\n",
       "      <td>26.004015</td>\n",
       "      <td>35.134979</td>\n",
       "      <td>46.362679</td>\n",
       "      <td>28.065481</td>\n",
       "      <td>-54.592117</td>\n",
       "      <td>19.476217</td>\n",
       "      <td>22.665514</td>\n",
       "      <td>-17.355413</td>\n",
       "      <td>56.056324</td>\n",
       "      <td>-66.309128</td>\n",
       "      <td>33.888325</td>\n",
       "      <td>14.050812</td>\n",
       "      <td>-9.611671</td>\n",
       "      <td>-0.249051</td>\n",
       "      <td>63.780502</td>\n",
       "      <td>-41.242207</td>\n",
       "      <td>-38.713936</td>\n",
       "      <td>35.662868</td>\n",
       "      <td>29.024122</td>\n",
       "      <td>-25.167414</td>\n",
       "      <td>-92.789589</td>\n",
       "      <td>-29.285501</td>\n",
       "      <td>47.776596</td>\n",
       "      <td>0.627758</td>\n",
       "      <td>-0.640528</td>\n",
       "      <td>-16.535437</td>\n",
       "      <td>34.853401</td>\n",
       "      <td>48.650223</td>\n",
       "      <td>-13.719818</td>\n",
       "      <td>-15.476673</td>\n",
       "      <td>5.131678</td>\n",
       "      <td>9.660119</td>\n",
       "      <td>55.053532</td>\n",
       "      <td>-16.085861</td>\n",
       "      <td>3.632786</td>\n",
       "      <td>4.122078</td>\n",
       "      <td>-18.373079</td>\n",
       "      <td>37.227283</td>\n",
       "      <td>53.485752</td>\n",
       "      <td>-5.783392</td>\n",
       "      <td>-24.802435</td>\n",
       "      <td>38.805614</td>\n",
       "      <td>4.854947</td>\n",
       "      <td>-60.464111</td>\n",
       "      <td>20.621580</td>\n",
       "      <td>-9.88452</td>\n",
       "      <td>80.360168</td>\n",
       "      <td>1.441724</td>\n",
       "      <td>-25.352222</td>\n",
       "      <td>-59.644367</td>\n",
       "      <td>-6.473505</td>\n",
       "      <td>-6.035451</td>\n",
       "      <td>62.187256</td>\n",
       "      <td>18.163960</td>\n",
       "      <td>27.530949</td>\n",
       "      <td>-1.169538</td>\n",
       "      <td>36.605747</td>\n",
       "      <td>32.508045</td>\n",
       "      <td>6.282441</td>\n",
       "      <td>-4.432948</td>\n",
       "      <td>-15.229724</td>\n",
       "      <td>-114.129578</td>\n",
       "      <td>22.284737</td>\n",
       "      <td>-27.113472</td>\n",
       "      <td>25.544212</td>\n",
       "      <td>2.130575</td>\n",
       "      <td>36.314854</td>\n",
       "      <td>20.966499</td>\n",
       "      <td>65.930969</td>\n",
       "      <td>20.400579</td>\n",
       "      <td>8.230969</td>\n",
       "      <td>55.773655</td>\n",
       "      <td>5.453974</td>\n",
       "      <td>43.124378</td>\n",
       "      <td>-37.356110</td>\n",
       "      <td>-29.907011</td>\n",
       "      <td>-9.024902</td>\n",
       "      <td>126.994133</td>\n",
       "      <td>34.766159</td>\n",
       "      <td>-2.734070</td>\n",
       "      <td>-3.582658</td>\n",
       "      <td>3.084803</td>\n",
       "      <td>27.793272</td>\n",
       "      <td>14.589323</td>\n",
       "      <td>-12.774110</td>\n",
       "      <td>-55.159611</td>\n",
       "      <td>6.359143</td>\n",
       "      <td>-38.623257</td>\n",
       "      <td>-75.735764</td>\n",
       "      <td>54.936657</td>\n",
       "      <td>-83.875412</td>\n",
       "      <td>-21.965757</td>\n",
       "      <td>-9.063822</td>\n",
       "      <td>5.702469</td>\n",
       "      <td>-45.232109</td>\n",
       "      <td>-6.673107</td>\n",
       "      <td>-60.377811</td>\n",
       "      <td>25.888378</td>\n",
       "      <td>2.055097</td>\n",
       "      <td>-35.393814</td>\n",
       "      <td>15.069509</td>\n",
       "      <td>-42.632935</td>\n",
       "      <td>62.669704</td>\n",
       "      <td>61.051582</td>\n",
       "      <td>-11.756592</td>\n",
       "      <td>-14.249672</td>\n",
       "      <td>-27.385521</td>\n",
       "      <td>-34.255928</td>\n",
       "      <td>-51.815311</td>\n",
       "      <td>42.243702</td>\n",
       "      <td>60.735878</td>\n",
       "      <td>-19.904369</td>\n",
       "      <td>-30.32637</td>\n",
       "      <td>-63.393421</td>\n",
       "      <td>45.122311</td>\n",
       "      <td>31.444427</td>\n",
       "      <td>-16.426874</td>\n",
       "      <td>42.630760</td>\n",
       "      <td>30.974825</td>\n",
       "      <td>75.452209</td>\n",
       "      <td>-18.469172</td>\n",
       "      <td>5.135574</td>\n",
       "      <td>23.939877</td>\n",
       "      <td>-24.031351</td>\n",
       "      <td>8.529229</td>\n",
       "      <td>46.969547</td>\n",
       "      <td>21.687927</td>\n",
       "      <td>-47.106823</td>\n",
       "      <td>28.188852</td>\n",
       "      <td>5.176566</td>\n",
       "      <td>-4.530713</td>\n",
       "      <td>-56.219097</td>\n",
       "      <td>11.410089</td>\n",
       "      <td>-48.072666</td>\n",
       "      <td>-28.044781</td>\n",
       "      <td>1.937657</td>\n",
       "      <td>-5.482918</td>\n",
       "      <td>1.621842</td>\n",
       "      <td>-51.277374</td>\n",
       "      <td>63.140606</td>\n",
       "      <td>-14.215036</td>\n",
       "      <td>-40.752468</td>\n",
       "      <td>23.413336</td>\n",
       "      <td>59.834492</td>\n",
       "      <td>-66.443268</td>\n",
       "      <td>19.228182</td>\n",
       "      <td>5.610026</td>\n",
       "      <td>34.219536</td>\n",
       "      <td>-87.626190</td>\n",
       "      <td>0.304163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.781757</td>\n",
       "      <td>4.097584</td>\n",
       "      <td>33.770538</td>\n",
       "      <td>-52.970398</td>\n",
       "      <td>35.076176</td>\n",
       "      <td>-53.870377</td>\n",
       "      <td>69.367332</td>\n",
       "      <td>65.722511</td>\n",
       "      <td>-50.706333</td>\n",
       "      <td>-23.730186</td>\n",
       "      <td>31.714771</td>\n",
       "      <td>-69.243896</td>\n",
       "      <td>-2.226767</td>\n",
       "      <td>-61.995678</td>\n",
       "      <td>-35.213467</td>\n",
       "      <td>13.084308</td>\n",
       "      <td>74.131653</td>\n",
       "      <td>-9.514544</td>\n",
       "      <td>3.434982</td>\n",
       "      <td>-0.358670</td>\n",
       "      <td>12.883670</td>\n",
       "      <td>-17.857742</td>\n",
       "      <td>-18.469833</td>\n",
       "      <td>-3.252056</td>\n",
       "      <td>-24.880127</td>\n",
       "      <td>-18.943834</td>\n",
       "      <td>-5.263479</td>\n",
       "      <td>74.564102</td>\n",
       "      <td>-25.299438</td>\n",
       "      <td>-81.828598</td>\n",
       "      <td>76.455376</td>\n",
       "      <td>-92.800827</td>\n",
       "      <td>83.915291</td>\n",
       "      <td>0.936572</td>\n",
       "      <td>6.528918</td>\n",
       "      <td>18.479195</td>\n",
       "      <td>45.366638</td>\n",
       "      <td>-50.195393</td>\n",
       "      <td>-0.936955</td>\n",
       "      <td>85.024307</td>\n",
       "      <td>50.302280</td>\n",
       "      <td>1.783827</td>\n",
       "      <td>25.892475</td>\n",
       "      <td>-46.916126</td>\n",
       "      <td>106.592667</td>\n",
       "      <td>47.494141</td>\n",
       "      <td>12.061660</td>\n",
       "      <td>69.745323</td>\n",
       "      <td>35.983543</td>\n",
       "      <td>34.040363</td>\n",
       "      <td>56.928944</td>\n",
       "      <td>24.181730</td>\n",
       "      <td>2.940058</td>\n",
       "      <td>47.268768</td>\n",
       "      <td>37.341602</td>\n",
       "      <td>-54.116222</td>\n",
       "      <td>-50.645077</td>\n",
       "      <td>-7.065079</td>\n",
       "      <td>6.404635</td>\n",
       "      <td>34.386093</td>\n",
       "      <td>-3.702037</td>\n",
       "      <td>-13.788336</td>\n",
       "      <td>22.491249</td>\n",
       "      <td>18.861820</td>\n",
       "      <td>-15.154586</td>\n",
       "      <td>16.279259</td>\n",
       "      <td>-59.317547</td>\n",
       "      <td>-16.240938</td>\n",
       "      <td>9.723481</td>\n",
       "      <td>-18.181213</td>\n",
       "      <td>71.568672</td>\n",
       "      <td>2.063491</td>\n",
       "      <td>66.902985</td>\n",
       "      <td>87.117622</td>\n",
       "      <td>-13.332965</td>\n",
       "      <td>-18.913530</td>\n",
       "      <td>-1.871500</td>\n",
       "      <td>-70.326675</td>\n",
       "      <td>34.756618</td>\n",
       "      <td>-67.667305</td>\n",
       "      <td>-50.186211</td>\n",
       "      <td>-10.073185</td>\n",
       "      <td>-22.258095</td>\n",
       "      <td>85.555191</td>\n",
       "      <td>28.131678</td>\n",
       "      <td>-36.180531</td>\n",
       "      <td>54.747360</td>\n",
       "      <td>10.368434</td>\n",
       "      <td>22.971647</td>\n",
       "      <td>75.64032</td>\n",
       "      <td>-73.110756</td>\n",
       "      <td>23.529118</td>\n",
       "      <td>1.495013</td>\n",
       "      <td>-41.872162</td>\n",
       "      <td>-36.192429</td>\n",
       "      <td>-13.098007</td>\n",
       "      <td>6.006214</td>\n",
       "      <td>7.949008</td>\n",
       "      <td>-31.214554</td>\n",
       "      <td>83.225288</td>\n",
       "      <td>17.541746</td>\n",
       "      <td>32.755009</td>\n",
       "      <td>73.842484</td>\n",
       "      <td>-54.210896</td>\n",
       "      <td>-7.439077</td>\n",
       "      <td>61.727352</td>\n",
       "      <td>27.086884</td>\n",
       "      <td>32.960567</td>\n",
       "      <td>-12.554884</td>\n",
       "      <td>27.169424</td>\n",
       "      <td>-1.269269</td>\n",
       "      <td>-26.844124</td>\n",
       "      <td>-65.929253</td>\n",
       "      <td>-32.224846</td>\n",
       "      <td>-10.435638</td>\n",
       "      <td>-16.959360</td>\n",
       "      <td>-19.749022</td>\n",
       "      <td>-16.381191</td>\n",
       "      <td>13.832074</td>\n",
       "      <td>19.208757</td>\n",
       "      <td>-40.585121</td>\n",
       "      <td>-5.338443</td>\n",
       "      <td>1.249931</td>\n",
       "      <td>39.847172</td>\n",
       "      <td>-1.036014</td>\n",
       "      <td>53.804890</td>\n",
       "      <td>-29.270229</td>\n",
       "      <td>-77.105850</td>\n",
       "      <td>37.048534</td>\n",
       "      <td>61.862297</td>\n",
       "      <td>-35.783703</td>\n",
       "      <td>7.436000</td>\n",
       "      <td>-2.366022</td>\n",
       "      <td>-94.514999</td>\n",
       "      <td>46.824245</td>\n",
       "      <td>6.355121</td>\n",
       "      <td>-38.427975</td>\n",
       "      <td>-35.940163</td>\n",
       "      <td>-14.532489</td>\n",
       "      <td>5.581335</td>\n",
       "      <td>3.115723</td>\n",
       "      <td>64.886055</td>\n",
       "      <td>38.551838</td>\n",
       "      <td>83.680038</td>\n",
       "      <td>17.547474</td>\n",
       "      <td>-20.674852</td>\n",
       "      <td>-3.421257</td>\n",
       "      <td>86.149635</td>\n",
       "      <td>-3.018294</td>\n",
       "      <td>-77.207886</td>\n",
       "      <td>-32.634155</td>\n",
       "      <td>47.232689</td>\n",
       "      <td>-1.147094</td>\n",
       "      <td>3.558857</td>\n",
       "      <td>25.887457</td>\n",
       "      <td>-9.442751</td>\n",
       "      <td>6.552187</td>\n",
       "      <td>-49.803207</td>\n",
       "      <td>-60.578808</td>\n",
       "      <td>26.666075</td>\n",
       "      <td>26.058527</td>\n",
       "      <td>55.428123</td>\n",
       "      <td>3.568920</td>\n",
       "      <td>61.524319</td>\n",
       "      <td>35.774387</td>\n",
       "      <td>-58.373615</td>\n",
       "      <td>28.120295</td>\n",
       "      <td>-8.350716</td>\n",
       "      <td>-91.827621</td>\n",
       "      <td>10.936516</td>\n",
       "      <td>96.777687</td>\n",
       "      <td>-44.885101</td>\n",
       "      <td>-18.965490</td>\n",
       "      <td>33.446156</td>\n",
       "      <td>6.730099</td>\n",
       "      <td>10.939882</td>\n",
       "      <td>41.259224</td>\n",
       "      <td>32.440918</td>\n",
       "      <td>21.940996</td>\n",
       "      <td>-46.607903</td>\n",
       "      <td>77.553055</td>\n",
       "      <td>35.663498</td>\n",
       "      <td>-701.057068</td>\n",
       "      <td>59.136826</td>\n",
       "      <td>36.461769</td>\n",
       "      <td>-69.833046</td>\n",
       "      <td>-16.253212</td>\n",
       "      <td>21.563925</td>\n",
       "      <td>-13.159373</td>\n",
       "      <td>-66.814049</td>\n",
       "      <td>-3.527200</td>\n",
       "      <td>58.490376</td>\n",
       "      <td>62.663109</td>\n",
       "      <td>22.512970</td>\n",
       "      <td>43.153545</td>\n",
       "      <td>10.558358</td>\n",
       "      <td>-34.473358</td>\n",
       "      <td>0.378257</td>\n",
       "      <td>-70.445541</td>\n",
       "      <td>-7.109326</td>\n",
       "      <td>-40.556732</td>\n",
       "      <td>63.685352</td>\n",
       "      <td>22.157600</td>\n",
       "      <td>76.098663</td>\n",
       "      <td>17.156544</td>\n",
       "      <td>26.766148</td>\n",
       "      <td>-38.957245</td>\n",
       "      <td>-42.740452</td>\n",
       "      <td>36.481571</td>\n",
       "      <td>26.419094</td>\n",
       "      <td>-0.509229</td>\n",
       "      <td>-10.880858</td>\n",
       "      <td>0.678111</td>\n",
       "      <td>24.425926</td>\n",
       "      <td>-1.179217</td>\n",
       "      <td>-59.708916</td>\n",
       "      <td>-8.315666</td>\n",
       "      <td>-73.074905</td>\n",
       "      <td>6.546713</td>\n",
       "      <td>51.197517</td>\n",
       "      <td>37.560524</td>\n",
       "      <td>-13.341130</td>\n",
       "      <td>23.226870</td>\n",
       "      <td>-48.236839</td>\n",
       "      <td>32.715908</td>\n",
       "      <td>76.452789</td>\n",
       "      <td>15.594794</td>\n",
       "      <td>6.282533</td>\n",
       "      <td>-65.215118</td>\n",
       "      <td>25.702726</td>\n",
       "      <td>-39.556969</td>\n",
       "      <td>-82.442917</td>\n",
       "      <td>-35.007191</td>\n",
       "      <td>-42.879025</td>\n",
       "      <td>24.330278</td>\n",
       "      <td>-21.673233</td>\n",
       "      <td>30.654428</td>\n",
       "      <td>27.047812</td>\n",
       "      <td>-64.179977</td>\n",
       "      <td>-46.198742</td>\n",
       "      <td>-6.694026</td>\n",
       "      <td>18.669853</td>\n",
       "      <td>12.298904</td>\n",
       "      <td>29.114168</td>\n",
       "      <td>22.449448</td>\n",
       "      <td>11.478456</td>\n",
       "      <td>10.055485</td>\n",
       "      <td>10.101665</td>\n",
       "      <td>45.896217</td>\n",
       "      <td>11.386663</td>\n",
       "      <td>...</td>\n",
       "      <td>69.135048</td>\n",
       "      <td>-8.229426</td>\n",
       "      <td>-48.755119</td>\n",
       "      <td>-54.854977</td>\n",
       "      <td>13.682758</td>\n",
       "      <td>30.875713</td>\n",
       "      <td>56.426014</td>\n",
       "      <td>52.365837</td>\n",
       "      <td>-18.080151</td>\n",
       "      <td>-25.782385</td>\n",
       "      <td>-29.840557</td>\n",
       "      <td>-6.940637</td>\n",
       "      <td>-38.330830</td>\n",
       "      <td>-51.861477</td>\n",
       "      <td>57.676926</td>\n",
       "      <td>-19.801537</td>\n",
       "      <td>23.582762</td>\n",
       "      <td>12.386575</td>\n",
       "      <td>-11.657601</td>\n",
       "      <td>7.731879</td>\n",
       "      <td>-19.793659</td>\n",
       "      <td>-15.660576</td>\n",
       "      <td>-36.961647</td>\n",
       "      <td>-7.526036</td>\n",
       "      <td>-7.984225</td>\n",
       "      <td>-16.927338</td>\n",
       "      <td>-25.360220</td>\n",
       "      <td>32.146355</td>\n",
       "      <td>-40.577457</td>\n",
       "      <td>-67.686501</td>\n",
       "      <td>62.160782</td>\n",
       "      <td>26.818821</td>\n",
       "      <td>-61.065094</td>\n",
       "      <td>-18.565794</td>\n",
       "      <td>51.237350</td>\n",
       "      <td>-22.384663</td>\n",
       "      <td>39.349548</td>\n",
       "      <td>-6.008307</td>\n",
       "      <td>-8.440115</td>\n",
       "      <td>6.232276</td>\n",
       "      <td>-22.233852</td>\n",
       "      <td>-42.032299</td>\n",
       "      <td>-7.935636</td>\n",
       "      <td>-8.700166</td>\n",
       "      <td>-7.132452</td>\n",
       "      <td>-52.420643</td>\n",
       "      <td>-5.111629</td>\n",
       "      <td>-4.545398</td>\n",
       "      <td>-37.752968</td>\n",
       "      <td>-3.952833</td>\n",
       "      <td>-5.339879</td>\n",
       "      <td>-49.226604</td>\n",
       "      <td>-62.153473</td>\n",
       "      <td>44.125664</td>\n",
       "      <td>25.087629</td>\n",
       "      <td>2.328262</td>\n",
       "      <td>-39.774136</td>\n",
       "      <td>-17.959019</td>\n",
       "      <td>-87.634155</td>\n",
       "      <td>-26.305857</td>\n",
       "      <td>-79.987190</td>\n",
       "      <td>-31.363033</td>\n",
       "      <td>10.732129</td>\n",
       "      <td>12.292964</td>\n",
       "      <td>26.926609</td>\n",
       "      <td>-17.296726</td>\n",
       "      <td>-27.251123</td>\n",
       "      <td>24.512394</td>\n",
       "      <td>15.188708</td>\n",
       "      <td>5.940803</td>\n",
       "      <td>-24.656870</td>\n",
       "      <td>39.334831</td>\n",
       "      <td>42.698627</td>\n",
       "      <td>23.200613</td>\n",
       "      <td>-9.602584</td>\n",
       "      <td>-52.570850</td>\n",
       "      <td>25.538303</td>\n",
       "      <td>22.826155</td>\n",
       "      <td>25.581871</td>\n",
       "      <td>-66.080856</td>\n",
       "      <td>13.876293</td>\n",
       "      <td>5.603144</td>\n",
       "      <td>10.007112</td>\n",
       "      <td>-35.752121</td>\n",
       "      <td>22.908913</td>\n",
       "      <td>14.595387</td>\n",
       "      <td>30.946651</td>\n",
       "      <td>42.495789</td>\n",
       "      <td>-27.375330</td>\n",
       "      <td>-43.270077</td>\n",
       "      <td>-15.200183</td>\n",
       "      <td>62.652618</td>\n",
       "      <td>-74.553902</td>\n",
       "      <td>50.580631</td>\n",
       "      <td>-3.656596</td>\n",
       "      <td>16.368549</td>\n",
       "      <td>3.378820</td>\n",
       "      <td>-25.933338</td>\n",
       "      <td>-35.934811</td>\n",
       "      <td>20.471802</td>\n",
       "      <td>45.657906</td>\n",
       "      <td>-4.519225</td>\n",
       "      <td>56.699558</td>\n",
       "      <td>-76.768562</td>\n",
       "      <td>-0.169955</td>\n",
       "      <td>17.322649</td>\n",
       "      <td>-16.722284</td>\n",
       "      <td>35.021332</td>\n",
       "      <td>-38.191982</td>\n",
       "      <td>-0.010109</td>\n",
       "      <td>15.540528</td>\n",
       "      <td>-43.623932</td>\n",
       "      <td>-6.006742</td>\n",
       "      <td>36.581947</td>\n",
       "      <td>-53.399601</td>\n",
       "      <td>-35.532761</td>\n",
       "      <td>-10.070759</td>\n",
       "      <td>16.685091</td>\n",
       "      <td>-17.973909</td>\n",
       "      <td>-59.485718</td>\n",
       "      <td>28.783703</td>\n",
       "      <td>72.225922</td>\n",
       "      <td>24.102087</td>\n",
       "      <td>0.467901</td>\n",
       "      <td>-15.490483</td>\n",
       "      <td>45.065613</td>\n",
       "      <td>9.999085</td>\n",
       "      <td>19.951864</td>\n",
       "      <td>-35.145607</td>\n",
       "      <td>31.665876</td>\n",
       "      <td>7.519873</td>\n",
       "      <td>39.973778</td>\n",
       "      <td>-15.860723</td>\n",
       "      <td>-35.143764</td>\n",
       "      <td>14.325870</td>\n",
       "      <td>-9.640446</td>\n",
       "      <td>17.120033</td>\n",
       "      <td>57.076801</td>\n",
       "      <td>-11.203368</td>\n",
       "      <td>-27.987064</td>\n",
       "      <td>47.509785</td>\n",
       "      <td>55.725769</td>\n",
       "      <td>-22.283710</td>\n",
       "      <td>-28.926678</td>\n",
       "      <td>-4.81697</td>\n",
       "      <td>28.530575</td>\n",
       "      <td>23.635176</td>\n",
       "      <td>-45.277985</td>\n",
       "      <td>-23.258886</td>\n",
       "      <td>-1.011455</td>\n",
       "      <td>-12.487021</td>\n",
       "      <td>17.967377</td>\n",
       "      <td>25.714384</td>\n",
       "      <td>27.632282</td>\n",
       "      <td>-5.885482</td>\n",
       "      <td>62.586960</td>\n",
       "      <td>-7.433270</td>\n",
       "      <td>12.896603</td>\n",
       "      <td>-75.470093</td>\n",
       "      <td>-7.197524</td>\n",
       "      <td>-148.826981</td>\n",
       "      <td>14.402157</td>\n",
       "      <td>-35.336430</td>\n",
       "      <td>-26.325832</td>\n",
       "      <td>-12.026991</td>\n",
       "      <td>25.135361</td>\n",
       "      <td>36.965797</td>\n",
       "      <td>80.248337</td>\n",
       "      <td>19.739058</td>\n",
       "      <td>11.816496</td>\n",
       "      <td>43.017479</td>\n",
       "      <td>71.601257</td>\n",
       "      <td>42.264927</td>\n",
       "      <td>-59.326012</td>\n",
       "      <td>33.009487</td>\n",
       "      <td>-51.034912</td>\n",
       "      <td>135.683395</td>\n",
       "      <td>36.200748</td>\n",
       "      <td>53.054661</td>\n",
       "      <td>-11.707137</td>\n",
       "      <td>5.921212</td>\n",
       "      <td>29.232967</td>\n",
       "      <td>17.548054</td>\n",
       "      <td>-7.796421</td>\n",
       "      <td>-87.072388</td>\n",
       "      <td>-30.496784</td>\n",
       "      <td>-5.669686</td>\n",
       "      <td>-79.243279</td>\n",
       "      <td>27.936291</td>\n",
       "      <td>-53.522293</td>\n",
       "      <td>-31.849136</td>\n",
       "      <td>37.759045</td>\n",
       "      <td>5.318216</td>\n",
       "      <td>-51.290955</td>\n",
       "      <td>-13.925587</td>\n",
       "      <td>-34.857845</td>\n",
       "      <td>1.536182</td>\n",
       "      <td>-3.323513</td>\n",
       "      <td>-28.850552</td>\n",
       "      <td>-8.305148</td>\n",
       "      <td>-59.968678</td>\n",
       "      <td>45.206234</td>\n",
       "      <td>67.988678</td>\n",
       "      <td>18.412048</td>\n",
       "      <td>10.519435</td>\n",
       "      <td>11.459414</td>\n",
       "      <td>-62.719833</td>\n",
       "      <td>-42.975548</td>\n",
       "      <td>40.328487</td>\n",
       "      <td>75.266747</td>\n",
       "      <td>-42.363605</td>\n",
       "      <td>-26.43548</td>\n",
       "      <td>-32.170567</td>\n",
       "      <td>42.448887</td>\n",
       "      <td>10.254427</td>\n",
       "      <td>-8.069320</td>\n",
       "      <td>18.809492</td>\n",
       "      <td>21.070810</td>\n",
       "      <td>43.179966</td>\n",
       "      <td>-25.773264</td>\n",
       "      <td>-12.347965</td>\n",
       "      <td>-0.047697</td>\n",
       "      <td>-34.867695</td>\n",
       "      <td>13.979957</td>\n",
       "      <td>60.014580</td>\n",
       "      <td>-29.743343</td>\n",
       "      <td>-51.690125</td>\n",
       "      <td>61.472511</td>\n",
       "      <td>-10.051567</td>\n",
       "      <td>-6.467038</td>\n",
       "      <td>-28.194164</td>\n",
       "      <td>1.915044</td>\n",
       "      <td>-63.596664</td>\n",
       "      <td>-20.064207</td>\n",
       "      <td>41.979794</td>\n",
       "      <td>1.743287</td>\n",
       "      <td>26.812840</td>\n",
       "      <td>-37.454453</td>\n",
       "      <td>50.571507</td>\n",
       "      <td>-68.717667</td>\n",
       "      <td>-7.080050</td>\n",
       "      <td>11.796075</td>\n",
       "      <td>69.840561</td>\n",
       "      <td>-41.899601</td>\n",
       "      <td>66.302803</td>\n",
       "      <td>-44.499969</td>\n",
       "      <td>7.006476</td>\n",
       "      <td>-51.791996</td>\n",
       "      <td>26.979214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5          6          7          8          9         10         11         12         13         14         15         16         17        18        19         20         21         22        23         24         25        26         27         28         29         30         31         32         33         34         35         36         37        38         39         40         41         42         43          44         45         46          47         48         49         50         51         52         53         54         55         56         57         58         59        60         61         62         63         64         65         66         67         68         69         70        71         72          73         74         75        76         77         78         79         80         81         82         83         84         85         86         87         88        89         90         91        92         93         94         95         96         97         98         99        100        101        102        103        104        105        106        107        108        109        110        111        112        113        114        115        116        117        118        119        120       121        122        123       124        125        126        127        128        129        130        131       132        133        134        135        136        137        138        139        140        141        142        143        144        145       146        147        148         149        150        151       152        153        154       155       156        157        158        159        160        161        162        163        164        165        166        167        168        169        170        171        172        173        174        175        176        177        178        179        180        181         182        183        184        185        186        187        188        189        190        191        192        193        194        195        196        197        198       199        200        201        202        203        204        205        206        207        208        209       210        211        212        213       214        215       216        217       218        219        220        221        222        223        224        225        226        227        228        229        230        231        232        233        234        235        236        237        238        239       240        241        242        243        244        245        246        247        248        249  ...        263       264        265        266        267        268        269        270        271        272        273        274        275        276        277        278        279        280        281        282        283        284        285        286        287        288        289        290        291        292        293        294        295        296        297        298        299       300        301       302        303        304       305        306        307        308        309        310        311        312        313        314        315        316        317        318        319        320        321        322        323        324        325        326        327        328        329        330        331        332        333        334        335        336        337        338        339        340        341        342        343        344        345        346        347        348        349        350        351        352        353        354        355        356       357        358        359        360        361        362        363        364        365        366        367        368        369        370        371        372        373        374       375        376        377        378        379        380        381        382        383        384        385       386        387        388        389        390        391        392       393        394        395        396        397        398        399        400        401        402        403        404        405        406      407        408        409        410        411       412        413        414        415        416       417        418        419        420        421        422         423        424        425        426        427        428        429        430        431        432        433        434        435        436        437        438         439        440        441        442       443        444        445        446        447        448        449        450        451        452        453        454       455        456        457        458        459       460        461        462        463        464        465        466        467        468        469        470        471        472        473       474        475        476        477        478        479        480        481        482        483        484        485        486        487        488        489        490        491       492        493        494        495        496        497       498        499        500        501        502        503        504        505        506        507        508        509        510        511  class\n",
       "0  29.556551  17.010456  31.388668 -59.826038  22.785978 -40.389637  63.132030  84.202469 -16.992029 -23.151354  43.602962 -49.792343  19.467327 -48.555180 -24.660128  23.610239  68.322159 -24.381779 -0.276951 -0.942664 -23.207857  22.574673 -25.435923 -8.476034  24.444014  -9.494406  4.695382  41.938358  -6.322362 -27.365942   3.681536 -79.809784  44.775520 -38.007759 -14.645349  14.415798   9.520861 -65.712296  5.570489  68.280205  14.519122 -17.480473  46.555386 -24.409235   60.196117  51.608974  20.218319  111.037277  20.729141   6.164212  40.037346  20.915165 -49.550720  -8.859608  17.657154 -64.730644   4.080844  25.650654  11.049224  39.231117  1.717297 -38.349976 -51.245243  62.720028  13.244308  56.438663 -29.142439  17.777523  16.075716  32.840721  73.021126 -1.106223  43.724163  110.561844   5.694403  -3.568817 -6.633853 -20.060560 -20.269951 -90.533340 -27.684378   2.509365   0.751597  59.583221 -31.484814 -37.511806 -12.505559  -8.637518  -2.638591  57.80661 -27.497965  70.625862  5.287386 -10.089879 -24.389599 -21.589941 -29.910767 -16.954830   5.852044  67.251831  12.467425  26.722008  74.665611 -45.834213 -27.048599  46.073143 -10.609952  -4.713609 -37.950188  22.113008  22.008308  19.812160 -87.337875 -59.416115  -5.307872  37.954582 -58.814655 -40.410023  67.103203  -9.136406 -10.947894 -9.197604 -19.980762  12.875637  4.647591  46.636059 -30.788107 -38.222744  36.502457   7.888191 -53.950577 -38.763725  4.683434 -76.262459 -12.632508  33.230438 -33.218147 -38.273003  60.519566 -55.548923  21.099266  24.372196  19.415829  48.136097  54.441914 -29.664719 -9.153059  61.043640 -31.490051 -112.432663 -19.331478  46.725330  9.383484  14.873656  -1.091031  1.271348  3.287261  -2.009163 -30.760050 -30.436218  14.952808  18.419436  29.612751  59.370369  34.593708 -19.635996  50.557961 -36.320408 -65.584396  30.164946  98.545799 -26.293577  -4.078367  10.270546  23.894571  -6.337955  16.216356  39.860119  74.214920 -38.005817  47.595745   5.964079 -849.917603  34.075047 -11.063751  17.136820 -25.357260  -0.509272  13.924665 -38.921009 -22.454096  34.336700  59.178024  39.083691  39.124416  -1.147380 -39.004841 -22.438942 -42.472679 -8.890372 -53.831310  15.963998   5.907835  63.313263  50.157925   6.551021 -43.251812 -40.627361  14.976477  -6.637170 -7.116735  10.555429 -25.185091  26.891237 -0.245195 -46.709976 -7.828382 -22.627840  1.802352  61.975979  29.072058   2.272201  24.476221  12.740591  23.313953  12.976930  41.204041  29.900862 -32.610695 -12.696423 -33.097515 -51.407215  12.968203   9.110934  17.925501 -20.052872  -4.232791  54.170078 -43.464672 -24.290796  5.506371  38.109146  -7.741554 -11.476376  -4.175846   2.860617  -8.206497  -1.903335  81.744766  33.409828  ...  19.161411  3.992487 -21.862389 -20.661762  11.231766  58.712265  27.022552  55.354141  36.132755 -61.173531 -25.761839 -10.999088 -64.929924 -40.931515  26.480803  -9.809968  43.818893 -23.315437 -11.041743 -51.430466  -8.270232  10.059938 -71.112213  19.979097  32.454544 -29.839439 -15.249496  18.712160 -16.958525 -64.093727  35.438137  -5.034605 -26.102144  -8.258367  40.100033 -33.159740  96.662415  2.077320  23.634781 -7.190621 -20.528114  10.953620  0.715644 -39.609165 -13.449426 -29.081539 -24.678802  39.423264 -31.450626  24.779564  16.608816 -22.171679 -28.825167  14.680913  39.313812  14.856753   0.017121  -7.328357 -47.685780 -26.487274 -48.240578 -50.572430  38.064968   0.701256  -6.009074 -73.383156  -8.664215  41.563145   0.892207 -22.694223 -11.169395  23.253736  27.601736  30.414112 -16.126633 -23.468775  51.786972  29.223194  22.808187 -56.214920   5.355277  13.041296  -6.660851 -41.371964  31.547384  11.386836  75.073738  21.275158  -3.354958 -65.665466 -10.052788  45.558231 -76.270134  29.730227 -1.623319 -12.565716 -56.678497 -24.496201 -33.074398  26.004015  35.134979  46.362679  28.065481 -54.592117  19.476217  22.665514 -17.355413  56.056324 -66.309128  33.888325  14.050812  -9.611671 -0.249051  63.780502 -41.242207 -38.713936  35.662868  29.024122 -25.167414 -92.789589 -29.285501  47.776596   0.627758 -0.640528 -16.535437  34.853401  48.650223 -13.719818 -15.476673   5.131678  9.660119  55.053532 -16.085861   3.632786   4.122078 -18.373079  37.227283  53.485752  -5.783392 -24.802435  38.805614   4.854947 -60.464111  20.621580 -9.88452  80.360168   1.441724 -25.352222 -59.644367 -6.473505  -6.035451  62.187256  18.163960  27.530949 -1.169538  36.605747  32.508045   6.282441  -4.432948 -15.229724 -114.129578  22.284737 -27.113472  25.544212   2.130575  36.314854  20.966499  65.930969  20.400579   8.230969  55.773655   5.453974  43.124378 -37.356110 -29.907011  -9.024902  126.994133  34.766159  -2.734070  -3.582658  3.084803  27.793272  14.589323 -12.774110 -55.159611   6.359143 -38.623257 -75.735764  54.936657 -83.875412 -21.965757  -9.063822  5.702469 -45.232109  -6.673107 -60.377811  25.888378  2.055097 -35.393814  15.069509 -42.632935  62.669704  61.051582 -11.756592 -14.249672 -27.385521 -34.255928 -51.815311  42.243702  60.735878 -19.904369 -30.32637 -63.393421  45.122311  31.444427 -16.426874  42.630760  30.974825  75.452209 -18.469172   5.135574  23.939877 -24.031351   8.529229  46.969547  21.687927 -47.106823  28.188852   5.176566 -4.530713 -56.219097  11.410089 -48.072666 -28.044781   1.937657 -5.482918   1.621842 -51.277374  63.140606 -14.215036 -40.752468  23.413336  59.834492 -66.443268  19.228182   5.610026  34.219536 -87.626190   0.304163      0\n",
       "1  19.781757   4.097584  33.770538 -52.970398  35.076176 -53.870377  69.367332  65.722511 -50.706333 -23.730186  31.714771 -69.243896  -2.226767 -61.995678 -35.213467  13.084308  74.131653  -9.514544  3.434982 -0.358670  12.883670 -17.857742 -18.469833 -3.252056 -24.880127 -18.943834 -5.263479  74.564102 -25.299438 -81.828598  76.455376 -92.800827  83.915291   0.936572   6.528918  18.479195  45.366638 -50.195393 -0.936955  85.024307  50.302280   1.783827  25.892475 -46.916126  106.592667  47.494141  12.061660   69.745323  35.983543  34.040363  56.928944  24.181730   2.940058  47.268768  37.341602 -54.116222 -50.645077  -7.065079   6.404635  34.386093 -3.702037 -13.788336  22.491249  18.861820 -15.154586  16.279259 -59.317547 -16.240938   9.723481 -18.181213  71.568672  2.063491  66.902985   87.117622 -13.332965 -18.913530 -1.871500 -70.326675  34.756618 -67.667305 -50.186211 -10.073185 -22.258095  85.555191  28.131678 -36.180531  54.747360  10.368434  22.971647  75.64032 -73.110756  23.529118  1.495013 -41.872162 -36.192429 -13.098007   6.006214   7.949008 -31.214554  83.225288  17.541746  32.755009  73.842484 -54.210896  -7.439077  61.727352  27.086884  32.960567 -12.554884  27.169424  -1.269269 -26.844124 -65.929253 -32.224846 -10.435638 -16.959360 -19.749022 -16.381191  13.832074  19.208757 -40.585121 -5.338443   1.249931  39.847172 -1.036014  53.804890 -29.270229 -77.105850  37.048534  61.862297 -35.783703   7.436000 -2.366022 -94.514999  46.824245   6.355121 -38.427975 -35.940163 -14.532489   5.581335   3.115723  64.886055  38.551838  83.680038  17.547474 -20.674852 -3.421257  86.149635  -3.018294  -77.207886 -32.634155  47.232689 -1.147094   3.558857  25.887457 -9.442751  6.552187 -49.803207 -60.578808  26.666075  26.058527  55.428123   3.568920  61.524319  35.774387 -58.373615  28.120295  -8.350716 -91.827621  10.936516  96.777687 -44.885101 -18.965490  33.446156   6.730099  10.939882  41.259224  32.440918  21.940996 -46.607903  77.553055  35.663498 -701.057068  59.136826  36.461769 -69.833046 -16.253212  21.563925 -13.159373 -66.814049  -3.527200  58.490376  62.663109  22.512970  43.153545  10.558358 -34.473358   0.378257 -70.445541 -7.109326 -40.556732  63.685352  22.157600  76.098663  17.156544  26.766148 -38.957245 -42.740452  36.481571  26.419094 -0.509229 -10.880858   0.678111  24.425926 -1.179217 -59.708916 -8.315666 -73.074905  6.546713  51.197517  37.560524 -13.341130  23.226870 -48.236839  32.715908  76.452789  15.594794   6.282533 -65.215118  25.702726 -39.556969 -82.442917 -35.007191 -42.879025  24.330278 -21.673233  30.654428  27.047812 -64.179977 -46.198742 -6.694026  18.669853  12.298904  29.114168  22.449448  11.478456  10.055485  10.101665  45.896217  11.386663  ...  69.135048 -8.229426 -48.755119 -54.854977  13.682758  30.875713  56.426014  52.365837 -18.080151 -25.782385 -29.840557  -6.940637 -38.330830 -51.861477  57.676926 -19.801537  23.582762  12.386575 -11.657601   7.731879 -19.793659 -15.660576 -36.961647  -7.526036  -7.984225 -16.927338 -25.360220  32.146355 -40.577457 -67.686501  62.160782  26.818821 -61.065094 -18.565794  51.237350 -22.384663  39.349548 -6.008307  -8.440115  6.232276 -22.233852 -42.032299 -7.935636  -8.700166  -7.132452 -52.420643  -5.111629  -4.545398 -37.752968  -3.952833  -5.339879 -49.226604 -62.153473  44.125664  25.087629   2.328262 -39.774136 -17.959019 -87.634155 -26.305857 -79.987190 -31.363033  10.732129  12.292964  26.926609 -17.296726 -27.251123  24.512394  15.188708   5.940803 -24.656870  39.334831  42.698627  23.200613  -9.602584 -52.570850  25.538303  22.826155  25.581871 -66.080856  13.876293   5.603144  10.007112 -35.752121  22.908913  14.595387  30.946651  42.495789 -27.375330 -43.270077 -15.200183  62.652618 -74.553902  50.580631 -3.656596  16.368549   3.378820 -25.933338 -35.934811  20.471802  45.657906  -4.519225  56.699558 -76.768562  -0.169955  17.322649 -16.722284  35.021332 -38.191982  -0.010109  15.540528 -43.623932 -6.006742  36.581947 -53.399601 -35.532761 -10.070759  16.685091 -17.973909 -59.485718  28.783703  72.225922  24.102087  0.467901 -15.490483  45.065613   9.999085  19.951864 -35.145607  31.665876  7.519873  39.973778 -15.860723 -35.143764  14.325870  -9.640446  17.120033  57.076801 -11.203368 -27.987064  47.509785  55.725769 -22.283710 -28.926678 -4.81697  28.530575  23.635176 -45.277985 -23.258886 -1.011455 -12.487021  17.967377  25.714384  27.632282 -5.885482  62.586960  -7.433270  12.896603 -75.470093  -7.197524 -148.826981  14.402157 -35.336430 -26.325832 -12.026991  25.135361  36.965797  80.248337  19.739058  11.816496  43.017479  71.601257  42.264927 -59.326012  33.009487 -51.034912  135.683395  36.200748  53.054661 -11.707137  5.921212  29.232967  17.548054  -7.796421 -87.072388 -30.496784  -5.669686 -79.243279  27.936291 -53.522293 -31.849136  37.759045  5.318216 -51.290955 -13.925587 -34.857845   1.536182 -3.323513 -28.850552  -8.305148 -59.968678  45.206234  67.988678  18.412048  10.519435  11.459414 -62.719833 -42.975548  40.328487  75.266747 -42.363605 -26.43548 -32.170567  42.448887  10.254427  -8.069320  18.809492  21.070810  43.179966 -25.773264 -12.347965  -0.047697 -34.867695  13.979957  60.014580 -29.743343 -51.690125  61.472511 -10.051567 -6.467038 -28.194164   1.915044 -63.596664 -20.064207  41.979794  1.743287  26.812840 -37.454453  50.571507 -68.717667  -7.080050  11.796075  69.840561 -41.899601  66.302803 -44.499969   7.006476 -51.791996  26.979214      0\n",
       "\n",
       "[2 rows x 513 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertVectors_fulldf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6d43e4",
   "metadata": {},
   "source": [
    "### Saving Bertvectors in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f5d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertVectors_fulldf.to_csv('Updated//bertVectors_fulldf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494ca8a2",
   "metadata": {},
   "source": [
    "### Loading dataframe BertVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dedb458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #creating a data frame\n",
    "bertVectors_fulldf = pd.read_csv(\"Updated//bertVectors_fulldf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52b5229",
   "metadata": {},
   "source": [
    "### Splitting dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6fa3f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=bertVectors_fulldf.drop('class',axis=1)\n",
    "y=bertVectors_fulldf['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad8bdf3",
   "metadata": {},
   "source": [
    "#### Using StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8434f0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e798288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in kfold.split(X, y):\n",
    "    # select rows\n",
    "    X_train, X_test = X.iloc[i], X.iloc[j]\n",
    "    y_train, y_test = y.iloc[i], y.iloc[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "215133f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4072, 512)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7bb9a4",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b832779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    " \n",
    "\n",
    "\n",
    "def metrics(X_test,y_test,clf):\n",
    "    predictions=clf.predict(X_test)\n",
    "    #predictions=(clf.predict_proba(X_test)[:,1] >= 0.3).astype(bool)\n",
    "    print(\"confusion_matrix :\")\n",
    "    print(confusion_matrix(y_test,predictions))\n",
    "    print(\"Accuracy Score :\")\n",
    "    print(accuracy_score(y_test, predictions))\n",
    "    print(\"Classification Report :\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(\"F1 score :\")\n",
    "    print(f1_score(y_test, predictions))\n",
    "    print(\"ROC AUC Score\")\n",
    "    y_pred_proba = clf.predict_proba(X_test)\n",
    "    print(roc_auc_score(y_test, y_pred_proba[:,1]) )\n",
    "    print(\"------------------------------\")\n",
    "\n",
    "    \n",
    "def model_comparison_table(X_test,y_test,classifier_list):\n",
    "    dict_clf={}\n",
    "    for clf_name,clf in classifier_list:\n",
    "        predictions=clf.predict(X_test)\n",
    "        y_pred_proba = clf.predict_proba(X_test)\n",
    "        accuracy=accuracy_score(y_test, predictions)\n",
    "        precision=precision_score(y_test,predictions,average='macro').round(2)\n",
    "        recall=recall_score(y_test,predictions)\n",
    "        f1score=f1_score(y_test,predictions).round(2)\n",
    "        ROC_AUC=roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "        dict_clf[clf_name]=[accuracy,precision,recall,f1score,ROC_AUC]\n",
    "    df_models_scores = pd.DataFrame(dict_clf, index=['Accuracy', 'Precision', 'Recall', 'F1 Score','roc_auc_score'])\n",
    "    return df_models_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18024342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b83306eb",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3a9e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit a basic Random Forest model on top of the vectors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf_model = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a223a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.81286836935167\n",
      "Confusion matrix : \n",
      " [[3008   54]\n",
      " [ 708  302]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89      3062\n",
      "           1       0.85      0.30      0.44      1010\n",
      "\n",
      "    accuracy                           0.81      4072\n",
      "   macro avg       0.83      0.64      0.66      4072\n",
      "weighted avg       0.82      0.81      0.78      4072\n",
      "\n",
      "Precision : 0.848314606741573\n",
      "Recall : 0.299009900990099\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to make predictions on the test data\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(\"Accuracy score : {}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Confusion matrix : \\n {}\".format(confusion_matrix(y_test, y_pred)))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision : {}\".format(precision))\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall : {}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403cdd5b",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b26df9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators =[int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth =[int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "#Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap\n",
    "              }\n",
    "pprint(random_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c32948ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf1=RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "041ee5dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=900; total time= 6.9min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=900; total time= 2.6min\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time= 5.0min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time= 2.6min\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time= 2.5min\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  46.8s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=600; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  42.5s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  16.1s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=800; total time= 3.2min\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time= 4.7min\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=900; total time= 6.9min\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time= 7.8min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time= 2.6min\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=700; total time= 4.5min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=800; total time= 3.2min\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700; total time= 4.7min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time= 3.6min\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time= 6.1min\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time= 3.7min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=900; total time= 3.8min\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time= 5.9min\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=600; total time= 2.5min\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  28.2s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time= 3.7min\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 6.3min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time= 4.6min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  49.5s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=700; total time= 3.1min\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=900; total time= 3.4min\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time= 2.7min\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time= 5.5min\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time= 7.8min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  25.7s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=700; total time= 1.8min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=900; total time= 4.0min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time= 1.8min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=900; total time= 3.4min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 4.4min\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 3.3min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 4.6min\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  40.7s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time= 1.9min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=900; total time= 3.3min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 4.3min\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=900; total time= 3.5min\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 2.1min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  47.7s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=900; total time= 4.4min\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  42.4s\n",
      "[CV] END bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=700; total time= 4.5min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  26.8s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=700; total time= 1.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 2.7min\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time= 5.2min\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time= 7.0min\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 3.4min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 4.2min\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  38.7s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=900; total time= 5.8min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 4.4min\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 3.4min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time= 3.6min\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time= 5.6min\n",
      "[CV] END bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  44.4s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=600; total time= 2.7min\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=600; total time= 4.0min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=700; total time= 1.9min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=600; total time= 2.3min\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  35.2s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  42.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  45.8s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  39.0s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time= 4.7min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  49.2s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=700; total time= 3.2min\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=900; total time= 3.5min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.8min\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time= 4.5min\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=900; total time= 5.9min\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  27.6s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time= 2.6min\n",
      "[CV] END bootstrap=True, max_depth=80, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=900; total time= 3.4min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=600; total time= 2.5min\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  37.7s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=900; total time= 6.2min\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700; total time= 4.8min\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time= 4.8min\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time= 3.0min\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=900; total time= 6.1min\n",
      "[CV] END bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  48.3s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time= 2.8min\n",
      "[CV] END bootstrap=True, max_depth=80, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=900; total time= 3.4min\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time= 5.8min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=900; total time= 4.4min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=600; total time= 2.5min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time= 2.8min\n",
      "[CV] END bootstrap=True, max_depth=80, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=900; total time= 3.4min\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=700; total time= 2.9min\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  45.9s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  58.2s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  38.9s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time= 6.0min\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 5.9min\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=900; total time= 6.8min\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time= 7.4min\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time= 4.8min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=900; total time= 4.0min\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time= 6.5min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=600; total time= 2.5min\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 6.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, max_depth=90, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 6.4min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time= 4.8min\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time= 4.5min\n",
      "[CV] END bootstrap=False, max_depth=100, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=600; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  34.6s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time= 5.3min\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time= 7.1min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=900; total time= 3.8min\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time= 2.5min\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  43.7s\n",
      "[CV] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  23.0s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  54.2s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  34.3s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=900; total time= 4.3min\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=900; total time= 5.8min\n",
      "[CV] END bootstrap=True, max_depth=90, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  25.7s\n",
      "[CV] END bootstrap=False, max_depth=100, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 3.2min\n",
      "[CV] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  25.2s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time= 5.4min\n",
      "[CV] END bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  44.8s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=600; total time= 2.5min\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  29.7s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=900; total time= 3.8min\n",
      "[CV] END bootstrap=True, max_depth=90, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  25.4s\n",
      "[CV] END bootstrap=False, max_depth=100, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time= 5.9min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=900; total time= 4.2min\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=600; total time= 3.9min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=900; total time= 3.9min\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=700; total time= 2.9min\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  42.8s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  52.8s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=800; total time= 3.0min\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time= 4.7min\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=900; total time= 3.9min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.9min\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time= 4.9min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=900; total time= 2.6min\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time= 5.0min\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time= 4.8min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 2.0min\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time= 5.0min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=900; total time= 2.6min\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time= 4.9min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time= 2.5min\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=600; total time= 2.4min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  32.7s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  42.9s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time= 4.4min\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time= 6.1min\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 6.2min\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 2.1min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  45.8s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=900; total time= 6.1min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time= 4.6min\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=600; total time= 2.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 2.7min\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  45.1s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=600; total time= 2.2min\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time= 5.7min\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=900; total time= 3.8min\n",
      "[CV] END bootstrap=True, max_depth=90, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  27.5s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=600; total time= 2.6min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 3.0min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  26.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  52.5s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  20.9s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 2.4min\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time= 2.8min\n",
      "[CV] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=900; total time= 3.9min\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 3.2min\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 6.6min\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=800; total time= 3.2min\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=600; total time= 4.1min\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 3.3min\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=700; total time= 3.1min\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=900; total time= 5.9min\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time= 4.6min\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=900; total time= 5.1min\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time= 3.1min\n",
      "[CV] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  26.1s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time= 5.6min\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700; total time= 4.8min\n",
      "[CV] END bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 6.2min\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time= 2.9min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  23.8s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time= 2.6min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=800; total time= 3.1min\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time= 4.5min\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=900; total time= 5.1min\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time= 6.4min\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=900; total time= 6.3min\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=600; total time= 4.3min\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 3.3min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time= 3.3min\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time= 2.5min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  23.6s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=900; total time= 4.2min\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=900; total time= 5.4min\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=700; total time= 4.1min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time= 3.5min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  51.1s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=900; total time= 4.5min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=600; total time= 2.3min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 6.3min\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=700; total time= 4.2min\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=900; total time= 3.7min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  53.3s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=700; total time= 3.3min\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=900; total time= 5.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  29.9s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  42.3s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time= 4.0min\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time= 7.3min\n",
      "[CV] END bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 6.4min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 4.2min\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  38.2s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=900; total time= 6.0min\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  41.4s\n",
      "[CV] END bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=700; total time= 4.4min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  24.0s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=700; total time= 4.1min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  29.2s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  39.5s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time= 3.8min\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=900; total time= 5.8min\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=900; total time= 5.4min\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=700; total time= 4.2min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(random_state=0),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         900, 1000]},\n",
       "                   random_state=42, return_train_score=True, verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random = RandomizedSearchCV(estimator=rf_clf1, param_distributions=random_grid,\n",
    "                              n_iter = 100, \n",
    "                              cv = 3, verbose=2, random_state=42, n_jobs=-1,\n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b794275e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 600,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 70,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 3.0min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  23.9s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=600; total time= 2.4min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.9s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  16.9s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=800; total time= 3.0min\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  40.4s\n",
      "[CV] END bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=700; total time= 4.2min\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time= 5.7min\n"
     ]
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b852a2fb",
   "metadata": {},
   "source": [
    "#### Using with Best Params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "327646fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.8197445972495089\n",
      "Confusion matrix : \n",
      " [[3014   48]\n",
      " [ 686  324]]\n"
     ]
    }
   ],
   "source": [
    "rf_clf_tuned=RandomForestClassifier(random_state=0,n_estimators=600,max_features='auto',max_depth=70,min_samples_split=2,min_samples_leaf=2,bootstrap=False)\n",
    "\n",
    "rf_clf_tuned.fit(X_train, y_train)\n",
    "\n",
    "pred1 = rf_clf_tuned.predict(X_test)\n",
    "print(\"Accuracy score : {}\".format(accuracy_score(y_test, pred1)))\n",
    "print(\"Confusion matrix : \\n {}\".format(confusion_matrix(y_test, pred1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ac8a0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score :\n",
      "0.46888567293777134\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89      3062\n",
      "           1       0.87      0.32      0.47      1010\n",
      "\n",
      "    accuracy                           0.82      4072\n",
      "   macro avg       0.84      0.65      0.68      4072\n",
      "weighted avg       0.83      0.82      0.79      4072\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score :\")\n",
    "print(f1_score(y_test, pred1))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2fea0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1457e97d",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae0716c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf=SVC(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd368ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.8266208251473477\n",
      "Confusion matrix : \n",
      " [[2967   95]\n",
      " [ 611  399]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89      3062\n",
      "           1       0.81      0.40      0.53      1010\n",
      "\n",
      "    accuracy                           0.83      4072\n",
      "   macro avg       0.82      0.68      0.71      4072\n",
      "weighted avg       0.82      0.83      0.80      4072\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "pred = svm_clf.predict(X_test)\n",
    "print(\"Accuracy score : {}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"Confusion matrix : \\n {}\".format(confusion_matrix(y_test, pred)))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfa06a3",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bb14189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': [0.1, 1, 10, 100, 1000],\n",
      " 'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
      " 'kernel': ['rbf', 'poly', 'sigmoid']}\n"
     ]
    }
   ],
   "source": [
    "# Create the random grid\n",
    "random_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 1000],\n",
    "               'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "               'kernel':  ['rbf', 'poly', 'sigmoid'],\n",
    "              }\n",
    "pprint(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0cccc5b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time= 1.1min\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time= 1.1min\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time= 5.3min\n",
      "[CV] END ...............C=1000, gamma=0.0001, kernel=sigmoid; total time=  41.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time= 3.4min\n",
      "[CV] END ..................C=1000, gamma=0.0001, kernel=poly; total time= 1.7min\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time= 5.9min\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=  55.1s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=  44.5s\n",
      "[CV] END ...............C=1000, gamma=0.0001, kernel=sigmoid; total time=  43.8s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time= 3.4min\n",
      "[CV] END ..................C=1000, gamma=0.0001, kernel=poly; total time= 1.6min\n",
      "[CV] END ......................C=1000, gamma=0.1, kernel=rbf; total time= 6.2min\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time= 4.1min\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=  52.8s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time= 3.4min\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time= 6.7min\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=  49.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time= 1.7min\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=  47.5s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time= 3.7min\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time= 5.6min\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time= 5.9min\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time= 3.6min\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=  47.6s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=  55.7s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time= 5.0min\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=  52.5s\n",
      "[CV] END ...............C=1000, gamma=0.0001, kernel=sigmoid; total time=  50.9s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time= 3.7min\n",
      "[CV] END ..................C=1000, gamma=0.0001, kernel=poly; total time= 1.6min\n",
      "[CV] END ......................C=1000, gamma=0.1, kernel=rbf; total time= 5.3min\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time= 5.0min\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time= 4.7min\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time= 1.7min\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time= 5.9min\n",
      "[CV] END ....................C=1000, gamma=1, kernel=sigmoid; total time=  59.3s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time= 6.5min\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time= 1.8min\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=  49.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time= 4.1min\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=  41.6s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time= 1.5min\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=  39.5s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time= 4.8min\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time= 4.5min\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time= 5.7min\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time= 4.3min\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time= 5.9min\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=  56.8s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=  55.5s\n",
      "[CV] END ...................C=0.1, gamma=0.0001, kernel=poly; total time= 1.8min\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=  55.8s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time= 4.8min\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time= 1.8min\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time= 4.0min\n",
      "[CV] END ...................C=100, gamma=0.0001, kernel=poly; total time= 1.5min\n",
      "[CV] END ....................C=1000, gamma=1, kernel=sigmoid; total time=  38.3s\n",
      "[CV] END ...................C=0.1, gamma=0.0001, kernel=poly; total time= 1.5min\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=  40.9s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time= 4.6min\n",
      "[CV] END ......................C=1000, gamma=0.1, kernel=rbf; total time= 4.5min\n",
      "[CV] END .................C=10, gamma=0.0001, kernel=sigmoid; total time=  46.5s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time= 6.5min\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time= 4.7min\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time= 5.8min\n",
      "[CV] END ...................C=100, gamma=0.0001, kernel=poly; total time= 1.6min\n",
      "[CV] END ....................C=1000, gamma=1, kernel=sigmoid; total time=  52.9s\n",
      "[CV] END ...................C=0.1, gamma=0.0001, kernel=poly; total time= 1.8min\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time= 5.5min\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time= 5.3min\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time= 3.9min\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=  51.9s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time= 5.8min\n",
      "[CV] END .....................C=1, gamma=0.0001, kernel=poly; total time= 1.9min\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=  49.1s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time= 6.1min\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time= 4.6min\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time= 3.7min\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time= 4.3min\n",
      "[CV] END .................C=10, gamma=0.0001, kernel=sigmoid; total time= 1.1min\n",
      "[CV] END ...................C=100, gamma=0.0001, kernel=poly; total time= 1.9min\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time= 1.7min\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=  46.5s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time= 3.2min\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time= 3.5min\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time= 1.0min\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time= 1.1min\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time= 6.0min\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time= 5.5min\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time= 3.3min\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=53.1min\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=55.4min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12094/17377509.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Fit the random search model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/python37env/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python37env/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m         evaluate_candidates(\n\u001b[1;32m   1767\u001b[0m             ParameterSampler(\n\u001b[0;32m-> 1768\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m             )\n\u001b[1;32m   1770\u001b[0m         )\n",
      "\u001b[0;32m~/.conda/envs/python37env/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
      "\u001b[0;32m~/.conda/envs/python37env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python37env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python37env/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python37env/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python37env/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "svm_clf1=SVC(random_state=0)\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator=svm_clf1, param_distributions=random_grid,\n",
    "                              n_iter = 50, \n",
    "                              cv = 3, verbose=2, random_state=42, n_jobs=-1,\n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bb3572",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee6d42b",
   "metadata": {},
   "source": [
    "#### Using with Best Params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7f05913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.8266208251473477\n",
      "Confusion matrix : \n",
      " [[2967   95]\n",
      " [ 611  399]]\n"
     ]
    }
   ],
   "source": [
    "svm_clf_tuned=SVC(random_state=0,probability=True)\n",
    "\n",
    "svm_clf_tuned.fit(X_train, y_train)\n",
    "\n",
    "pred1 = svm_clf_tuned.predict(X_test)\n",
    "print(\"Accuracy score : {}\".format(accuracy_score(y_test, pred1)))\n",
    "print(\"Confusion matrix : \\n {}\".format(confusion_matrix(y_test, pred1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7afd574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score :\n",
      "0.5305851063829787\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89      3062\n",
      "           1       0.81      0.40      0.53      1010\n",
      "\n",
      "    accuracy                           0.83      4072\n",
      "   macro avg       0.82      0.68      0.71      4072\n",
      "weighted avg       0.82      0.83      0.80      4072\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score :\")\n",
    "print(f1_score(y_test, pred1))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc28a134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12664f9b",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33653bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create KNN Object.\n",
    "knn_clf = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ab8f50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.81213163064833\n",
      "Confusion matrix : \n",
      " [[2794  268]\n",
      " [ 497  513]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      3062\n",
      "           1       0.66      0.51      0.57      1010\n",
      "\n",
      "    accuracy                           0.81      4072\n",
      "   macro avg       0.75      0.71      0.73      4072\n",
      "weighted avg       0.80      0.81      0.80      4072\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_clf.fit(X_train,y_train)\n",
    "\n",
    "pred = knn_clf.predict(X_test)\n",
    "print(\"Accuracy score : {}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"Confusion matrix : \\n {}\".format(confusion_matrix(y_test, pred)))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede806e4",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c84c79ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf_size': [1,\n",
      "               2,\n",
      "               3,\n",
      "               4,\n",
      "               5,\n",
      "               6,\n",
      "               7,\n",
      "               8,\n",
      "               9,\n",
      "               10,\n",
      "               11,\n",
      "               12,\n",
      "               13,\n",
      "               14,\n",
      "               15,\n",
      "               16,\n",
      "               17,\n",
      "               18,\n",
      "               19,\n",
      "               20,\n",
      "               21,\n",
      "               22,\n",
      "               23,\n",
      "               24,\n",
      "               25,\n",
      "               26,\n",
      "               27,\n",
      "               28,\n",
      "               29,\n",
      "               30,\n",
      "               31,\n",
      "               32,\n",
      "               33,\n",
      "               34,\n",
      "               35,\n",
      "               36,\n",
      "               37,\n",
      "               38,\n",
      "               39,\n",
      "               40,\n",
      "               41,\n",
      "               42,\n",
      "               43,\n",
      "               44,\n",
      "               45,\n",
      "               46,\n",
      "               47,\n",
      "               48,\n",
      "               49],\n",
      " 'n_neighbors': [1,\n",
      "                 2,\n",
      "                 3,\n",
      "                 4,\n",
      "                 5,\n",
      "                 6,\n",
      "                 7,\n",
      "                 8,\n",
      "                 9,\n",
      "                 10,\n",
      "                 11,\n",
      "                 12,\n",
      "                 13,\n",
      "                 14,\n",
      "                 15,\n",
      "                 16,\n",
      "                 17,\n",
      "                 18,\n",
      "                 19,\n",
      "                 20,\n",
      "                 21,\n",
      "                 22,\n",
      "                 23,\n",
      "                 24,\n",
      "                 25,\n",
      "                 26,\n",
      "                 27,\n",
      "                 28,\n",
      "                 29],\n",
      " 'p': [1, 2]}\n"
     ]
    }
   ],
   "source": [
    "# Create the random grid\n",
    "random_grid = {\n",
    "    'leaf_size': list(range(1,50)),\n",
    "               'n_neighbors': list(range(1,30)),\n",
    "               'p':  [1,2],\n",
    "              }\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f734f68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END ..................leaf_size=17, n_neighbors=19, p=2; total time=   4.9s\n",
      "[CV] END ..................leaf_size=14, n_neighbors=29, p=2; total time=   3.4s\n",
      "[CV] END ...................leaf_size=10, n_neighbors=6, p=2; total time=   3.6s\n",
      "[CV] END ..................leaf_size=15, n_neighbors=15, p=2; total time=   3.1s\n",
      "[CV] END ...................leaf_size=38, n_neighbors=8, p=2; total time=   3.4s\n",
      "[CV] END ..................leaf_size=41, n_neighbors=27, p=2; total time=   3.0s\n",
      "[CV] END ...................leaf_size=14, n_neighbors=6, p=2; total time=   3.3s\n",
      "[CV] END ...................leaf_size=3, n_neighbors=13, p=2; total time=   3.0s\n",
      "[CV] END ..................leaf_size=18, n_neighbors=16, p=2; total time=   3.0s\n",
      "[CV] END ..................leaf_size=21, n_neighbors=24, p=1; total time= 2.1min\n",
      "[CV] END ..................leaf_size=27, n_neighbors=16, p=1; total time= 2.3min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=KNeighborsClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'leaf_size': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...],\n",
       "                                        'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                                                        9, 10, 11, 12, 13, 14,\n",
       "                                                        15, 16, 17, 18, 19, 20,\n",
       "                                                        21, 22, 23, 24, 25, 26,\n",
       "                                                        27, 28, 29],\n",
       "                                        'p': [1, 2]},\n",
       "                   random_state=42, return_train_score=True, verbose=2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "knn_clf1=KNeighborsClassifier()\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator=knn_clf1, param_distributions=random_grid,\n",
    "                              n_iter = 100, \n",
    "                              cv = 3, verbose=2, random_state=42, n_jobs=-1,\n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46b1a292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p': 1, 'n_neighbors': 27, 'leaf_size': 13}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346c3a3d",
   "metadata": {},
   "source": [
    "#### Using with Best Params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71335898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.8180255402750491\n",
      "Confusion matrix : \n",
      " [[2908  154]\n",
      " [ 587  423]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      3062\n",
      "           1       0.73      0.42      0.53      1010\n",
      "\n",
      "    accuracy                           0.82      4072\n",
      "   macro avg       0.78      0.68      0.71      4072\n",
      "weighted avg       0.81      0.82      0.80      4072\n",
      "\n",
      "F1 score :\n",
      "0.5330812854442344\n"
     ]
    }
   ],
   "source": [
    "knn_clf_tuned=KNeighborsClassifier(n_neighbors=27,leaf_size=13,p=1)\n",
    "knn_clf_tuned.fit(X_train,y_train)\n",
    "\n",
    "pred = knn_clf_tuned.predict(X_test)\n",
    "print(\"Accuracy score : {}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"Confusion matrix : \\n {}\".format(confusion_matrix(y_test, pred)))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, pred))\n",
    "print(\"F1 score :\")\n",
    "print(f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d44c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398ab98f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f878c31",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ac17299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.8295677799607073\n",
      "Confusion matrix : \n",
      " [[2889  173]\n",
      " [ 521  489]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89      3062\n",
      "           1       0.74      0.48      0.58      1010\n",
      "\n",
      "    accuracy                           0.83      4072\n",
      "   macro avg       0.79      0.71      0.74      4072\n",
      "weighted avg       0.82      0.83      0.82      4072\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create KNN Object.\n",
    "xg_clf=XGBClassifier(random_state=0)\n",
    "\n",
    "xg_clf.fit(X_train,y_train)\n",
    "\n",
    "pred = xg_clf.predict(X_test)\n",
    "print(\"Accuracy score : {}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"Confusion matrix : \\n {}\".format(confusion_matrix(y_test, pred)))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6303507c",
   "metadata": {},
   "source": [
    "#### HYperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b69446c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': [1e-05, 0.01, 0.1, 1, 10, 50, 100],\n",
      " 'colsample_bylevel': array([0.5, 0.6, 0.7, 0.8, 0.9]),\n",
      " 'colsample_bytree': array([0.5, 0.6, 0.7, 0.8, 0.9]),\n",
      " 'gamma': [1,\n",
      "           2,\n",
      "           3,\n",
      "           4,\n",
      "           5,\n",
      "           6,\n",
      "           7,\n",
      "           8,\n",
      "           9,\n",
      "           10,\n",
      "           11,\n",
      "           12,\n",
      "           13,\n",
      "           14,\n",
      "           15,\n",
      "           16,\n",
      "           17,\n",
      "           18,\n",
      "           19,\n",
      "           20,\n",
      "           21,\n",
      "           22,\n",
      "           23,\n",
      "           24,\n",
      "           25,\n",
      "           26,\n",
      "           27,\n",
      "           28,\n",
      "           29],\n",
      " 'learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4],\n",
      " 'max_depth': range(3, 15, 2),\n",
      " 'min_child_weight': range(1, 6, 2),\n",
      " 'n_estimators': [100, 250, 500],\n",
      " 'scale_pos_weight': range(1, 5),\n",
      " 'subsample': array([0.5, 0.6, 0.7, 0.8, 0.9])}\n"
     ]
    }
   ],
   "source": [
    "# Create the random grid\n",
    "random_grid = {\n",
    "    'min_child_weight': range(1,6,2),\n",
    "    'gamma': list(range(1,30)),\n",
    "    'max_depth':  range(3,15,2),\n",
    "    'alpha': [1e-5, 1e-2, 0.1,1,10,50, 100],\n",
    "    'subsample':np.arange(0.5, 1.0, 0.1),\n",
    "    'scale_pos_weight':range(1,5,1),\n",
    "    'colsample_bytree':np.arange(0.5, 1.0, 0.1),\n",
    "    'n_estimators':[100, 250, 500],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4],\n",
    "    'colsample_bylevel': np.arange(0.5, 1.0, 0.1),\n",
    "    }\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c5ea979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END alpha=50, colsample_bylevel=0.6, colsample_bytree=0.8999999999999999, gamma=19, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=2, subsample=0.7999999999999999; total time=  48.8s\n",
      "[CV] END alpha=0.01, colsample_bylevel=0.5, colsample_bytree=0.7999999999999999, gamma=26, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=100, scale_pos_weight=3, subsample=0.7999999999999999; total time=  53.2s\n",
      "[CV] END alpha=0.1, colsample_bylevel=0.7, colsample_bytree=0.6, gamma=27, learning_rate=0.2, max_depth=11, min_child_weight=3, n_estimators=250, scale_pos_weight=4, subsample=0.8999999999999999; total time= 3.6min\n",
      "[CV] END alpha=50, colsample_bylevel=0.5, colsample_bytree=0.7999999999999999, gamma=22, learning_rate=0.4, max_depth=5, min_child_weight=5, n_estimators=500, scale_pos_weight=4, subsample=0.5; total time= 2.4min\n",
      "[CV] END alpha=100, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, gamma=1, learning_rate=0.3, max_depth=11, min_child_weight=3, n_estimators=100, scale_pos_weight=4, subsample=0.8999999999999999; total time= 1.3min\n",
      "[CV] END alpha=100, colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, gamma=3, learning_rate=0.1, max_depth=13, min_child_weight=5, n_estimators=250, scale_pos_weight=2, subsample=0.8999999999999999; total time= 3.1min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, gamma=15, learning_rate=0.2, max_depth=5, min_child_weight=3, n_estimators=100, scale_pos_weight=3, subsample=0.7; total time=  49.1s\n",
      "[CV] END alpha=0.01, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, gamma=9, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=100, scale_pos_weight=3, subsample=0.7; total time= 1.2min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.5, colsample_bytree=0.5, gamma=20, learning_rate=0.01, max_depth=11, min_child_weight=1, n_estimators=250, scale_pos_weight=4, subsample=0.5; total time= 1.7min\n",
      "[CV] END alpha=1, colsample_bylevel=0.6, colsample_bytree=0.8999999999999999, gamma=16, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=500, scale_pos_weight=1, subsample=0.7999999999999999; total time= 2.3min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, gamma=18, learning_rate=0.4, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=4, subsample=0.7; total time= 3.3min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, gamma=26, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=1, subsample=0.7; total time=  51.3s\n",
      "[CV] END alpha=10, colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, gamma=24, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=100, scale_pos_weight=3, subsample=0.6; total time= 1.2min\n",
      "[CV] END alpha=100, colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, gamma=24, learning_rate=0.3, max_depth=11, min_child_weight=3, n_estimators=100, scale_pos_weight=1, subsample=0.7; total time= 1.0min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=13, learning_rate=0.2, max_depth=11, min_child_weight=1, n_estimators=100, scale_pos_weight=3, subsample=0.7999999999999999; total time= 1.1min\n",
      "[CV] END alpha=100, colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, gamma=15, learning_rate=0.4, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=0.7; total time= 2.3min\n",
      "[CV] END alpha=0.1, colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, gamma=28, learning_rate=0.4, max_depth=3, min_child_weight=5, n_estimators=500, scale_pos_weight=3, subsample=0.5; total time= 1.8min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.7999999999999999, colsample_bytree=0.5, gamma=15, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=100, scale_pos_weight=2, subsample=0.7999999999999999; total time= 1.0min\n",
      "[CV] END alpha=50, colsample_bylevel=0.5, colsample_bytree=0.7999999999999999, gamma=28, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=0.5; total time= 1.5min\n",
      "[CV] END alpha=50, colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, gamma=2, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=250, scale_pos_weight=3, subsample=0.6; total time= 1.3min\n",
      "[CV] END alpha=50, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=4, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, scale_pos_weight=3, subsample=0.7999999999999999; total time=  23.0s\n",
      "[CV] END alpha=50, colsample_bylevel=0.7999999999999999, colsample_bytree=0.6, gamma=21, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=250, scale_pos_weight=2, subsample=0.5; total time=  53.2s\n",
      "[CV] END alpha=0.01, colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, gamma=15, learning_rate=0.2, max_depth=3, min_child_weight=1, n_estimators=100, scale_pos_weight=2, subsample=0.8999999999999999; total time=  30.3s\n",
      "[CV] END alpha=10, colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, gamma=4, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=0.6; total time= 3.2min\n",
      "[CV] END alpha=1, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=1, learning_rate=0.3, max_depth=11, min_child_weight=5, n_estimators=100, scale_pos_weight=3, subsample=0.7; total time=  53.7s\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, gamma=11, learning_rate=0.2, max_depth=3, min_child_weight=1, n_estimators=100, scale_pos_weight=2, subsample=0.8999999999999999; total time=  32.5s\n",
      "[CV] END alpha=0.1, colsample_bylevel=0.7, colsample_bytree=0.7, gamma=14, learning_rate=0.4, max_depth=13, min_child_weight=1, n_estimators=100, scale_pos_weight=3, subsample=0.7999999999999999; total time= 1.9min\n",
      "[CV] END alpha=50, colsample_bylevel=0.5, colsample_bytree=0.7999999999999999, gamma=2, learning_rate=0.2, max_depth=9, min_child_weight=1, n_estimators=250, scale_pos_weight=2, subsample=0.5; total time= 1.4min\n",
      "[CV] END alpha=50, colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, gamma=16, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=0.8999999999999999; total time= 1.8min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, gamma=2, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=500, scale_pos_weight=4, subsample=0.5; total time= 3.2min\n",
      "[CV] END alpha=10, colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, gamma=4, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=0.6; total time= 3.4min\n",
      "[CV] END alpha=10, colsample_bylevel=0.5, colsample_bytree=0.7, gamma=23, learning_rate=0.2, max_depth=5, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=0.7999999999999999; total time=  34.2s\n",
      "[CV] END alpha=0.01, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=24, learning_rate=0.2, max_depth=9, min_child_weight=1, n_estimators=100, scale_pos_weight=2, subsample=0.5; total time=  46.1s\n",
      "[CV] END alpha=10, colsample_bylevel=0.5, colsample_bytree=0.6, gamma=28, learning_rate=0.1, max_depth=13, min_child_weight=1, n_estimators=500, scale_pos_weight=4, subsample=0.6; total time= 5.0min\n",
      "[CV] END alpha=0.1, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, gamma=22, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=0.6; total time= 5.4min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=13, learning_rate=0.2, max_depth=11, min_child_weight=1, n_estimators=100, scale_pos_weight=3, subsample=0.7999999999999999; total time= 1.2min\n",
      "[CV] END alpha=0.01, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, gamma=9, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=100, scale_pos_weight=3, subsample=0.7; total time= 1.3min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.5, colsample_bytree=0.5, gamma=20, learning_rate=0.01, max_depth=11, min_child_weight=1, n_estimators=250, scale_pos_weight=4, subsample=0.5; total time= 1.7min\n",
      "[CV] END alpha=50, colsample_bylevel=0.7, colsample_bytree=0.7, gamma=9, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100, scale_pos_weight=4, subsample=0.5; total time=  22.9s\n",
      "[CV] END alpha=10, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=20, learning_rate=0.2, max_depth=13, min_child_weight=1, n_estimators=100, scale_pos_weight=3, subsample=0.5; total time= 1.2min\n",
      "[CV] END alpha=0.1, colsample_bylevel=0.7999999999999999, colsample_bytree=0.8999999999999999, gamma=29, learning_rate=0.2, max_depth=5, min_child_weight=3, n_estimators=100, scale_pos_weight=3, subsample=0.8999999999999999; total time= 1.1min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.6, colsample_bytree=0.8999999999999999, gamma=11, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=0.8999999999999999; total time=  29.3s\n",
      "[CV] END alpha=0.1, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, gamma=22, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=0.6; total time= 5.5min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=13, learning_rate=0.2, max_depth=11, min_child_weight=1, n_estimators=100, scale_pos_weight=3, subsample=0.7999999999999999; total time= 1.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=100, colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, gamma=15, learning_rate=0.4, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=0.7; total time= 2.3min\n",
      "[CV] END alpha=0.01, colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, gamma=2, learning_rate=0.01, max_depth=13, min_child_weight=3, n_estimators=250, scale_pos_weight=3, subsample=0.5; total time= 4.0min\n",
      "[CV] END alpha=0.1, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, gamma=22, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=0.6; total time= 5.4min\n",
      "[CV] END alpha=100, colsample_bylevel=0.7999999999999999, colsample_bytree=0.8999999999999999, gamma=3, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=500, scale_pos_weight=1, subsample=0.5; total time= 1.6min\n",
      "[CV] END alpha=50, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, gamma=28, learning_rate=0.4, max_depth=13, min_child_weight=1, n_estimators=250, scale_pos_weight=3, subsample=0.5; total time= 4.2min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.7999999999999999, colsample_bytree=0.5, gamma=15, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=100, scale_pos_weight=2, subsample=0.7999999999999999; total time= 1.1min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, gamma=18, learning_rate=0.4, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=4, subsample=0.7; total time= 3.3min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, gamma=26, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=1, subsample=0.7; total time=  51.3s\n",
      "[CV] END alpha=10, colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, gamma=24, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=100, scale_pos_weight=3, subsample=0.6; total time= 1.2min\n",
      "[CV] END alpha=100, colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, gamma=24, learning_rate=0.3, max_depth=11, min_child_weight=3, n_estimators=100, scale_pos_weight=1, subsample=0.7; total time= 1.0min\n",
      "[CV] END alpha=100, colsample_bylevel=0.7999999999999999, colsample_bytree=0.8999999999999999, gamma=3, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=500, scale_pos_weight=1, subsample=0.5; total time= 1.6min\n",
      "[CV] END alpha=50, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=21, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=250, scale_pos_weight=2, subsample=0.7; total time= 2.1min\n",
      "[CV] END alpha=0.1, colsample_bylevel=0.6, colsample_bytree=0.8999999999999999, gamma=13, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=100, scale_pos_weight=2, subsample=0.7999999999999999; total time= 1.1min\n",
      "[CV] END alpha=100, colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, gamma=9, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=0.6; total time=  45.1s\n",
      "[CV] END alpha=10, colsample_bylevel=0.7999999999999999, colsample_bytree=0.8999999999999999, gamma=18, learning_rate=0.4, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=3, subsample=0.5; total time= 2.5min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, gamma=2, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=500, scale_pos_weight=4, subsample=0.5; total time= 3.2min\n",
      "[CV] END alpha=10, colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, gamma=4, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=0.6; total time= 3.0min\n",
      "[CV] END alpha=100, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=29, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=0.8999999999999999; total time=  41.6s\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, gamma=8, learning_rate=0.3, max_depth=13, min_child_weight=5, n_estimators=250, scale_pos_weight=2, subsample=0.8999999999999999; total time= 5.3min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, gamma=18, learning_rate=0.4, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=4, subsample=0.7; total time= 3.3min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, gamma=26, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=1, subsample=0.7; total time=  50.7s\n",
      "[CV] END alpha=10, colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, gamma=24, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=100, scale_pos_weight=3, subsample=0.6; total time= 1.2min\n",
      "[CV] END alpha=100, colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, gamma=24, learning_rate=0.3, max_depth=11, min_child_weight=3, n_estimators=100, scale_pos_weight=1, subsample=0.7; total time= 1.0min\n",
      "[CV] END alpha=100, colsample_bylevel=0.7999999999999999, colsample_bytree=0.8999999999999999, gamma=3, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=500, scale_pos_weight=1, subsample=0.5; total time= 1.6min\n",
      "[CV] END alpha=50, colsample_bylevel=0.6, colsample_bytree=0.8999999999999999, gamma=19, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=2, subsample=0.7999999999999999; total time=  48.2s\n",
      "[CV] END alpha=0.01, colsample_bylevel=0.5, colsample_bytree=0.7999999999999999, gamma=26, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=100, scale_pos_weight=3, subsample=0.7999999999999999; total time=  51.2s\n",
      "[CV] END alpha=0.01, colsample_bylevel=0.7, colsample_bytree=0.6, gamma=6, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=2, subsample=0.8999999999999999; total time=  39.6s\n",
      "[CV] END alpha=0.01, colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, gamma=2, learning_rate=0.01, max_depth=13, min_child_weight=3, n_estimators=250, scale_pos_weight=3, subsample=0.5; total time= 3.9min\n",
      "[CV] END alpha=10, colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, gamma=20, learning_rate=0.1, max_depth=11, min_child_weight=3, n_estimators=250, scale_pos_weight=4, subsample=0.8999999999999999; total time= 7.1min\n",
      "[CV] END alpha=0.1, colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, gamma=7, learning_rate=0.2, max_depth=3, min_child_weight=3, n_estimators=250, scale_pos_weight=3, subsample=0.5; total time= 1.0min\n",
      "[CV] END alpha=0.1, colsample_bylevel=0.6, colsample_bytree=0.7999999999999999, gamma=19, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=500, scale_pos_weight=3, subsample=0.6; total time= 3.2min\n",
      "[CV] END alpha=100, colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, gamma=3, learning_rate=0.01, max_depth=11, min_child_weight=3, n_estimators=250, scale_pos_weight=1, subsample=0.7; total time= 3.9min\n",
      "[CV] END alpha=50, colsample_bylevel=0.7999999999999999, colsample_bytree=0.6, gamma=21, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=250, scale_pos_weight=2, subsample=0.5; total time=  55.2s\n",
      "[CV] END alpha=0.01, colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, gamma=15, learning_rate=0.2, max_depth=3, min_child_weight=1, n_estimators=100, scale_pos_weight=2, subsample=0.8999999999999999; total time=  33.2s\n",
      "[CV] END alpha=0.1, colsample_bylevel=0.5, colsample_bytree=0.8999999999999999, gamma=24, learning_rate=0.4, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=4, subsample=0.7; total time= 2.3min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, gamma=15, learning_rate=0.2, max_depth=5, min_child_weight=3, n_estimators=100, scale_pos_weight=3, subsample=0.7; total time=  49.6s\n",
      "[CV] END alpha=100, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=29, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=0.8999999999999999; total time=  40.7s\n",
      "[CV] END alpha=1, colsample_bylevel=0.7999999999999999, colsample_bytree=0.7999999999999999, gamma=5, learning_rate=0.01, max_depth=11, min_child_weight=3, n_estimators=100, scale_pos_weight=2, subsample=0.6; total time= 1.6min\n",
      "[CV] END alpha=0.01, colsample_bylevel=0.7, colsample_bytree=0.6, gamma=6, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=2, subsample=0.8999999999999999; total time=  37.3s\n",
      "[CV] END alpha=0.01, colsample_bylevel=0.7, colsample_bytree=0.6, gamma=20, learning_rate=0.2, max_depth=9, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=0.6; total time= 4.6min\n",
      "[CV] END alpha=0.01, colsample_bylevel=0.7999999999999999, colsample_bytree=0.5, gamma=25, learning_rate=0.4, max_depth=3, min_child_weight=3, n_estimators=100, scale_pos_weight=2, subsample=0.6; total time=  19.9s\n",
      "[CV] END alpha=0.1, colsample_bylevel=0.7999999999999999, colsample_bytree=0.8999999999999999, gamma=27, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, scale_pos_weight=4, subsample=0.7; total time= 4.8min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, gamma=15, learning_rate=0.2, max_depth=5, min_child_weight=3, n_estimators=100, scale_pos_weight=3, subsample=0.7; total time=  43.4s\n",
      "[CV] END alpha=100, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=29, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=0.8999999999999999; total time=  41.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=50, colsample_bylevel=0.7, colsample_bytree=0.6, gamma=1, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=0.5; total time= 1.5min\n",
      "[CV] END alpha=0.1, colsample_bylevel=0.7, colsample_bytree=0.7, gamma=14, learning_rate=0.4, max_depth=13, min_child_weight=1, n_estimators=100, scale_pos_weight=3, subsample=0.7999999999999999; total time= 1.8min\n",
      "[CV] END alpha=1, colsample_bylevel=0.6, colsample_bytree=0.5, gamma=23, learning_rate=0.1, max_depth=11, min_child_weight=1, n_estimators=250, scale_pos_weight=4, subsample=0.7; total time= 2.5min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.6, colsample_bytree=0.8999999999999999, gamma=11, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=0.8999999999999999; total time=  29.6s\n",
      "[CV] END alpha=10, colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, gamma=20, learning_rate=0.1, max_depth=11, min_child_weight=3, n_estimators=250, scale_pos_weight=4, subsample=0.8999999999999999; total time= 7.3min\n",
      "[CV] END alpha=50, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=21, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=250, scale_pos_weight=2, subsample=0.7; total time= 3.0min\n",
      "[CV] END alpha=50, colsample_bylevel=0.7, colsample_bytree=0.7, gamma=9, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100, scale_pos_weight=4, subsample=0.5; total time=  23.0s\n",
      "[CV] END alpha=10, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=20, learning_rate=0.2, max_depth=13, min_child_weight=1, n_estimators=100, scale_pos_weight=3, subsample=0.5; total time= 1.3min\n",
      "[CV] END alpha=0.1, colsample_bylevel=0.7999999999999999, colsample_bytree=0.8999999999999999, gamma=29, learning_rate=0.2, max_depth=5, min_child_weight=3, n_estimators=100, scale_pos_weight=3, subsample=0.8999999999999999; total time= 1.1min\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.6, colsample_bytree=0.8999999999999999, gamma=11, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=0.8999999999999999; total time=  28.7s\n",
      "[CV] END alpha=10, colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, gamma=20, learning_rate=0.1, max_depth=11, min_child_weight=3, n_estimators=250, scale_pos_weight=4, subsample=0.8999999999999999; total time= 7.3min\n",
      "[CV] END alpha=50, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=21, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=250, scale_pos_weight=2, subsample=0.7; total time= 2.1min\n",
      "[CV] END alpha=0.1, colsample_bylevel=0.6, colsample_bytree=0.8999999999999999, gamma=13, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=100, scale_pos_weight=2, subsample=0.7999999999999999; total time= 1.2min\n",
      "[CV] END alpha=1, colsample_bylevel=0.6, colsample_bytree=0.5, gamma=23, learning_rate=0.1, max_depth=11, min_child_weight=1, n_estimators=250, scale_pos_weight=4, subsample=0.7; total time= 2.5min\n",
      "[CV] END alpha=10, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=17, learning_rate=0.2, max_depth=9, min_child_weight=3, n_estimators=100, scale_pos_weight=1, subsample=0.8999999999999999; total time= 1.3min\n",
      "[CV] END alpha=0.01, colsample_bylevel=0.5, colsample_bytree=0.6, gamma=16, learning_rate=0.2, max_depth=7, min_child_weight=5, n_estimators=500, scale_pos_weight=4, subsample=0.8999999999999999; total time= 3.1min\n",
      "[CV] END alpha=50, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=6, learning_rate=0.4, max_depth=9, min_child_weight=3, n_estimators=100, scale_pos_weight=3, subsample=0.6; total time=  39.7s\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.5, colsample_bytree=0.7999999999999999, gamma=18, learning_rate=0.2, max_depth=13, min_child_weight=1, n_estimators=250, scale_pos_weight=2, subsample=0.5; total time= 2.7min\n",
      "[CV] END alpha=50, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, gamma=5, learning_rate=0.2, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=0.8999999999999999; total time= 3.3min\n",
      "[CV] END alpha=1, colsample_bylevel=0.6, colsample_bytree=0.5, gamma=23, learning_rate=0.1, max_depth=11, min_child_weight=1, n_estimators=250, scale_pos_weight=4, subsample=0.7; total time= 2.5min\n",
      "[CV] END alpha=0.1, colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, gamma=13, learning_rate=0.01, max_depth=11, min_child_weight=1, n_estimators=100, scale_pos_weight=1, subsample=0.6; total time= 1.4min\n",
      "[CV] END alpha=0.01, colsample_bylevel=0.5, colsample_bytree=0.6, gamma=16, learning_rate=0.2, max_depth=7, min_child_weight=5, n_estimators=500, scale_pos_weight=4, subsample=0.8999999999999999; total time= 3.1min\n",
      "[CV] END alpha=50, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=6, learning_rate=0.4, max_depth=9, min_child_weight=3, n_estimators=100, scale_pos_weight=3, subsample=0.6; total time=  39.3s\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.5, colsample_bytree=0.7999999999999999, gamma=18, learning_rate=0.2, max_depth=13, min_child_weight=1, n_estimators=250, scale_pos_weight=2, subsample=0.5; total time= 2.7min\n",
      "[CV] END alpha=0.1, colsample_bylevel=0.7, colsample_bytree=0.6, gamma=15, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=0.8999999999999999; total time=  42.5s\n",
      "[CV] END alpha=10, colsample_bylevel=0.7999999999999999, colsample_bytree=0.7999999999999999, gamma=13, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=250, scale_pos_weight=2, subsample=0.7; total time= 3.1min\n",
      "[CV] END alpha=0.01, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=26, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=100, scale_pos_weight=1, subsample=0.6; total time=  33.2s\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=11, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=0.6; total time= 1.5min\n",
      "[CV] END alpha=10, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=17, learning_rate=0.2, max_depth=9, min_child_weight=3, n_estimators=100, scale_pos_weight=1, subsample=0.8999999999999999; total time= 1.3min\n",
      "[CV] END alpha=0.01, colsample_bylevel=0.5, colsample_bytree=0.6, gamma=16, learning_rate=0.2, max_depth=7, min_child_weight=5, n_estimators=500, scale_pos_weight=4, subsample=0.8999999999999999; total time= 3.1min\n",
      "[CV] END alpha=50, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=6, learning_rate=0.4, max_depth=9, min_child_weight=3, n_estimators=100, scale_pos_weight=3, subsample=0.6; total time=  39.6s\n",
      "[CV] END alpha=1e-05, colsample_bylevel=0.5, colsample_bytree=0.7999999999999999, gamma=18, learning_rate=0.2, max_depth=13, min_child_weight=1, n_estimators=250, scale_pos_weight=2, subsample=0.5; total time= 2.8min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, gamma=None,\n",
       "                                           gpu_id=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None, max_bin=None,...\n",
       "                                        'colsample_bytree': array([0.5, 0.6, 0.7, 0.8, 0.9]),\n",
       "                                        'gamma': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                  11, 12, 13, 14, 15, 16, 17,\n",
       "                                                  18, 19, 20, 21, 22, 23, 24,\n",
       "                                                  25, 26, 27, 28, 29],\n",
       "                                        'learning_rate': [0.01, 0.1, 0.2, 0.3,\n",
       "                                                          0.4],\n",
       "                                        'max_depth': range(3, 15, 2),\n",
       "                                        'min_child_weight': range(1, 6, 2),\n",
       "                                        'n_estimators': [100, 250, 500],\n",
       "                                        'scale_pos_weight': range(1, 5),\n",
       "                                        'subsample': array([0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "                   random_state=42, return_train_score=True, verbose=2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "xg_clf1=XGBClassifier(random_state=0)\n",
    "\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator=xg_clf1, param_distributions=random_grid,\n",
    "                              n_iter = 100, \n",
    "                              cv = 3, verbose=2, random_state=42, n_jobs=-1,\n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f99a392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.7,\n",
       " 'scale_pos_weight': 2,\n",
       " 'n_estimators': 500,\n",
       " 'min_child_weight': 1,\n",
       " 'max_depth': 5,\n",
       " 'learning_rate': 0.1,\n",
       " 'gamma': 3,\n",
       " 'colsample_bytree': 0.7999999999999999,\n",
       " 'colsample_bylevel': 0.8999999999999999,\n",
       " 'alpha': 1}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52903d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.8320235756385069\n",
      "Confusion matrix : \n",
      " [[2834  228]\n",
      " [ 456  554]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89      3062\n",
      "           1       0.71      0.55      0.62      1010\n",
      "\n",
      "    accuracy                           0.83      4072\n",
      "   macro avg       0.78      0.74      0.76      4072\n",
      "weighted avg       0.82      0.83      0.82      4072\n",
      "\n",
      "F1 score :\n",
      "0.6183035714285714\n"
     ]
    }
   ],
   "source": [
    "xg_clf_tuned=XGBClassifier(subsample=0.7,scale_pos_weight=2,n_estimators=500,min_child_weight=3,max_depth=5,learning_rate=0.1,\n",
    "                     gamma=3,colsample_bytree=0.79,colsample_bylevel=0.89,alpha=1)\n",
    "xg_clf_tuned.fit(X_train,y_train)\n",
    "\n",
    "pred = xg_clf_tuned.predict(X_test)\n",
    "print(\"Accuracy score : {}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"Confusion matrix : \\n {}\".format(confusion_matrix(y_test, pred)))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, pred))\n",
    "print(\"F1 score :\")\n",
    "print(f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ee49fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3927128d",
   "metadata": {},
   "source": [
    "### Naiva Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3cb40fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.6863948919449901\n",
      "Confusion matrix : \n",
      " [[2102  960]\n",
      " [ 317  693]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77      3062\n",
      "           1       0.42      0.69      0.52      1010\n",
      "\n",
      "    accuracy                           0.69      4072\n",
      "   macro avg       0.64      0.69      0.64      4072\n",
      "weighted avg       0.76      0.69      0.71      4072\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_clf=GaussianNB()\n",
    "#p = Pipeline([('Normalizing',MinMaxScaler()),('MultinomialNB',MultinomialNB())])\n",
    "nb_clf.fit(X_train,y_train) \n",
    "\n",
    "pred = nb_clf.predict(X_test)\n",
    "print(\"Accuracy score : {}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"Confusion matrix : \\n {}\".format(confusion_matrix(y_test, pred)))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e373780",
   "metadata": {},
   "source": [
    "#### HYperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9777f1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': [1e-05, 0.0001, 0.001, 0.1, 1, 10, 100, 1000]}\n"
     ]
    }
   ],
   "source": [
    "# Create the random grid\n",
    "random_grid = {\n",
    "    'var_smoothing': [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100,1000]\n",
    "#    # 'class_prior':[True,False],\n",
    "#     'fit_prior':[True,False]\n",
    "              }\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce7e05c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=GaussianNB(), n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'var_smoothing': [1e-05, 0.0001, 0.001,\n",
       "                                                          0.1, 1, 10, 100,\n",
       "                                                          1000]},\n",
       "                   random_state=42, return_train_score=True, verbose=2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nb_clf1=GaussianNB()\n",
    "\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator=nb_clf1, param_distributions=random_grid,\n",
    "                              n_iter = 100, \n",
    "                              cv = 3, verbose=2, random_state=42, n_jobs=-1,\n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "806eb695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'priors': None, 'var_smoothing': 1e-09}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a620a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_smoothing': 1}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "afcfca6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.7721021611001965\n",
      "Confusion matrix : \n",
      " [[3039   23]\n",
      " [ 905  105]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87      3062\n",
      "           1       0.82      0.10      0.18      1010\n",
      "\n",
      "    accuracy                           0.77      4072\n",
      "   macro avg       0.80      0.55      0.53      4072\n",
      "weighted avg       0.78      0.77      0.70      4072\n",
      "\n",
      "F1 score :\n",
      "0.18453427065026362\n"
     ]
    }
   ],
   "source": [
    "nb_clf_tuned=GaussianNB(var_smoothing=0.5)\n",
    "\n",
    "nb_clf_tuned.fit(X_train,y_train)\n",
    "\n",
    "pred = nb_clf_tuned.predict(X_test )\n",
    "print(\"Accuracy score : {}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"Confusion matrix : \\n {}\".format(confusion_matrix(y_test, pred)))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, pred))\n",
    "print(\"F1 score :\")\n",
    "print(f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1a1869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "134d989f",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ad9f939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f69ee08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.8172888015717092\n",
      "Confusion matrix : \n",
      " [[2846  216]\n",
      " [ 528  482]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      3062\n",
      "           1       0.69      0.48      0.56      1010\n",
      "\n",
      "    accuracy                           0.82      4072\n",
      "   macro avg       0.77      0.70      0.72      4072\n",
      "weighted avg       0.81      0.82      0.81      4072\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logticreg_clf=LogisticRegression()\n",
    "\n",
    "logticreg_clf.fit(X_train,y_train)\n",
    "\n",
    "pred = logticreg_clf.predict(X_test)\n",
    "print(\"Accuracy score : {}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"Confusion matrix : \\n {}\".format(confusion_matrix(y_test, pred)))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7cc2e2",
   "metadata": {},
   "source": [
    "#### HYperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43a7db77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': [100, 10, 1.0, 0.1, 0.01],\n",
      " 'penalty': ['l1', 'l2', 'elasticnet'],\n",
      " 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n"
     ]
    }
   ],
   "source": [
    "# Create the random grid\n",
    "random_grid = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "     'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "    'penalty':['l1','l2','elasticnet']\n",
    "              }\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "efcac2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 75 candidates, totalling 225 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=LogisticRegression(), n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'C': [100, 10, 1.0, 0.1, 0.01],\n",
       "                                        'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                                        'solver': ['newton-cg', 'lbfgs',\n",
       "                                                   'liblinear', 'sag',\n",
       "                                                   'saga']},\n",
       "                   random_state=42, return_train_score=True, verbose=2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "logticreg_clf_tuned=LogisticRegression()\n",
    "\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator=logticreg_clf_tuned, param_distributions=random_grid,\n",
    "                              n_iter = 100, \n",
    "                              cv = 3, verbose=2, random_state=42, n_jobs=-1,\n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "350e8516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'liblinear', 'penalty': 'l1', 'C': 0.01}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2f42b6",
   "metadata": {},
   "source": [
    "### Using Best Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c0af2d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.8175343811394892\n",
      "Confusion matrix : \n",
      " [[2855  207]\n",
      " [ 536  474]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      3062\n",
      "           1       0.70      0.47      0.56      1010\n",
      "\n",
      "    accuracy                           0.82      4072\n",
      "   macro avg       0.77      0.70      0.72      4072\n",
      "weighted avg       0.81      0.82      0.80      4072\n",
      "\n",
      "F1 score :\n",
      "0.5606150206978119\n"
     ]
    }
   ],
   "source": [
    "logticreg_clf_tuned=LogisticRegression(solver='liblinear',penalty='l1',C=0.01)\n",
    "\n",
    "logticreg_clf_tuned.fit(X_train,y_train)\n",
    "\n",
    "pred = logticreg_clf_tuned.predict(X_test)\n",
    "print(\"Accuracy score : {}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"Confusion matrix : \\n {}\".format(confusion_matrix(y_test, pred)))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, pred))\n",
    "print(\"F1 score :\")\n",
    "print(f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d700982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0065cc84",
   "metadata": {},
   "source": [
    "### Consolidating all classifiers accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "436316f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [('Logistic Regression',logticreg_clf_tuned),('Naive Bayes',nb_clf_tuned),('Xgboost',xg_clf_tuned),\n",
    "              ('KNN',knn_clf_tuned),('Random Forest',rf_clf_tuned),(\"SVM\",svm_clf_tuned)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7df3657c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Xgboost</th>\n",
       "      <td>0.832024</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.548515</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.839054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.826621</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.395050</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.825470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.824165</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.344554</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.822716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.818026</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.418812</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.815061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.817534</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.469307</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.816043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.772102</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.103960</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.740386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Precision    Recall  F1 Score  roc_auc_score\n",
       "Xgboost              0.832024       0.78  0.548515      0.62       0.839054\n",
       "SVM                  0.826621       0.82  0.395050      0.53       0.825470\n",
       "Random Forest        0.824165       0.84  0.344554      0.49       0.822716\n",
       "KNN                  0.818026       0.78  0.418812      0.53       0.815061\n",
       "Logistic Regression  0.817534       0.77  0.469307      0.56       0.816043\n",
       "Naive Bayes          0.772102       0.80  0.103960      0.18       0.740386"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_scores=model_comparison_table(X_test,y_test,classifiers)\n",
    "df_model_scores.head(20).T.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a7aebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa14c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5bcea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1100400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ccf402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
